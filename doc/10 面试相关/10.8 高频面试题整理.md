## 0 基础
### 1、java的object方法有哪些
- hashcode、equals
- getClass
- toString
- notify、notifyAll
- wait
- clone
- finalize


### 2. 哪些场景下，子类需要重写 equals 方法和 hashCode 方法？     
Object的equals只比较了对象的引用地址，重写equals()是为了实现自己的区分逻辑，

==如果重写的equals()方法确定了两个对象相等，则这两个对象的hashCode必须返回相同的值==
，Object的hashCode是一个native本地方法，所以必须重写    

重写hashCode()是为了提高hash tables的使用效率，  
如果equals()方法确定了两个对象不相等，这个两个对象的hashCode还是有可能相等的。     
但是不同的对象应该有着不同的hashCode，这样可以提高hash tables的使用效率。

对于equals不相同而hashCode相同的元素集合，在哈希表中会以链表或者红黑树的形式储存

### 3. 列表中学生按照年龄排序      
重写compareTo
```java
Collections.sort(list, new Comparator<User>() {
   @Override
   public int compare(User o1, User o2) {
       // 升序 
       return o1.getAge().compareTo(o2.getAge());
       // 降序
       // return o2.getAge().compareTo(o1.getAge());
   }
});
```


---

## 1 Java 集合

### 1.1 List 
支持按索引访问，存入和取出顺序不变，元素可重复，可以保存null值   

#### ArrayList底层数据结构
Object数组，

#### add 方法逻辑
1、 检查是否需要扩容     
新的长度不长于 MAX_ARRAY_SIZE 时，增长为原长度的1.5倍，否则赋值为 MAX_ARRAY_SIZE
```text
int newCapacity = oldCapacity + (oldCapacity >> 1);

elementData = Arrays.copyOf(elementData, newCapacity);
```
2、 在末尾添加元素

####  for/foreach 循环删除list中 满足条件的对象Java 有没有问题？
有问题，快速失败机制，会抛出异常 [ConcurrentModificationException的原因以及解决措施](https://my.oschina.net/hosee/blog/612718)

单线程解决方案：使用 迭代器的remove方法

多线程 两种解决方案：     
1. 在使用iterator迭代的时候使用synchronized或者Lock进行同步；（一个个迭代就和单线程一样了）

2. 使用并发容器CopyOnWriteArrayList代替ArrayList和Vector。

#### LinkedList
双向列表，增删快

##### add 方法
```java
void linkLast(E e) {
    final Node<E> l = last;
    final Node<E> newNode = new Node<>(l, e, null);
    last = newNode;
    if (l == null)
        first = newNode;
    else
        l.next = newNode;
    size++;
    modCount++;
}
```

### HashSet 、
内部持有 HashMap引用， key 可以为 null, 不能重复

### HashMap

#### 底层数据结构
数组 + 链表 （长度超过 8 转换成红黑树）

#### put 方法流程
1、 初始化第一次调用 put，    
根据初始化给的初始容量（会向上调整为2的n次幂），初始化 hash表（Node<K,V>[] table）

2、 根据 key的 hash值取模，获取key在 hash表（Node数组）中的存放位置，   
取模方法：
```java
(n - 1) & hash
```

如果当前索引位置没有值，在当前位置初始化 Node     

如果当前索引位置有值（hash冲突），     
   - 如果是重复的key，用新值替换旧值，返回旧值
```java
if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))
```
   - 遍历查看当前节点的下一节点，直到找到重复的key，用新值替换旧值，返回旧值；     
   或者找到null节点，在当前位置初始化 Node，        
   如果链表的长度 >= 8 并且hash表长度大于64，将当前列表转换成红黑树，否则reHash()     
   

3、 modCount 记录修改次数 
```java
transient int modCount;
```

4、 当前 Node数量自增1 ，与当前阈值比较，判断是否需要扩容

#### HashMap 和 HashTable 区别？
##### 1. 数据结构     
HashTable : 数组 + 链表

HashMap ： 数组 + 链表 （长度超过 8 转换成红黑树）

##### 2. 线程安全性
HashTable : 线程安全 ， Synchronized 修饰方法，当前实例被锁住，只能串行调用其他方法

HashMap ： 线程不安全

### 为啥会线程不安全？ 如何才能得到一个线程安全的HashMap？
Java7在多线程操作HashMap时可能引起死循环，原因是扩容转移后前后链表顺序倒置，在转移过程中修改了原来链表中节点的引用关系。

Java8在同样的前提下并不会引起死循环，原因是扩容转移后前后链表顺序不变，保持之前节点的引用关系。

put/get方法都没有加同步锁，多线程情况最容易出现的就是：     
无法保证上一秒put的值，下一秒get的时候还是原值，所以线程安全还是无法保证。

使用 ConcurrentHashMap、 或者 Collections.synchronizedMap()



---



## 2 Java并发相关
定义： 多个线程读写 可变的共享资源 时，跟单个线程操作结果一致

### 2.1 原理篇

#### 比较一下 volatile 和 Synchronized
volatile 修饰变量，可以保证 线程之间共享资源 的 可见性

Synchronized 可以修改代码块，方法，类 ；可以保证 保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行


### 2.2 JDK 工具篇

#### [2.2.0 线程池](http://concurrent.redspider.group/article/03/12.html)
线程池顶层接口是Executor接口，ThreadPoolExecutor 是这个接口的实现类

##### 线程池原理
使用线程池主要有以下三个原因：

- 控制并发的数量。并发数量过多，可能会导致资源消耗过多，从而造成服务器崩溃。（主要原因）
- 创建/销毁线程需要消耗系统资源，线程池可以复用已创建的线程。
- 可以对线程做统一管理 (传入 ThreadFactory ，设置线程池名称 、线程优先级、是否为守护线程)

ThreadPoolExecutor在创建线程时，会将线程封装成工作线程worker,并放入工作线程组中，       
然后这个worker反复从阻塞队列中拿任务去执行。

##### 线程池构造函数的参数，默认值
涉及到5~7个参数，必须的5个参数

```text
int corePoolSize：该线程池中核心线程数最大值

    核心线程：线程池中有两类线程，核心线程和非核心线程。核心线程默认情况下会一直存在于线程池中，即使这个核心线程什么都不干（铁饭碗），而非核心线程如果长时间的闲置，就会被销毁（临时工）。

int maximumPoolSize：该线程池中线程总数最大值 。

    该值等于核心线程数量 + 非核心线程数量。

long keepAliveTime：非核心线程闲置超时时长。

    非核心线程如果处于闲置状态超过该值，就会被销毁。如果设置allowCoreThreadTimeOut(true)，则会也作用于核心线程。

TimeUnit unit：keepAliveTime的单位。

    TimeUnit是一个枚举类型 ，包括以下属性：
    
    NANOSECONDS ： 1微毫秒 = 1微秒 / 1000 MICROSECONDS ： 1微秒 = 1毫秒 / 1000 MILLISECONDS ： 1毫秒 = 1秒 /1000 SECONDS ： 秒 MINUTES ： 分 HOURS ： 小时 DAYS ： 天
    
BlockingQueue workQueue：阻塞队列，维护着等待执行的Runnable任务对象。

    常用的几个阻塞队列：
    
    LinkedBlockingQueue
    
    链式阻塞队列，底层数据结构是链表，默认大小是Integer.MAX_VALUE，也可以指定大小。
    
    ArrayBlockingQueue
    
    数组阻塞队列，底层数据结构是数组，需要指定队列的大小。
    
    SynchronousQueue
    
    同步队列，内部容量为0，每个put操作必须等待一个take操作，反之亦然。
    
    DelayQueue
    
    延迟队列，该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 
```

两个非必须的参数。
```text
ThreadFactory threadFactory

    创建线程的工厂 ，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂     

RejectedExecutionHandler handler

    拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为 ：
```

##### 总结一下处理流程
```text
1. 线程总数量 < corePoolSize，无论线程是否空闲，都会新建一个核心线程执行任务（让核心线程数量快速达到corePoolSize，在核心线程数量 < corePoolSize时）。注意，这一步需要获得全局锁。
2. 线程总数量 >= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了线程复用）。
3. 当缓存队列满了，说明这个时候任务已经多到爆棚，需要一些“临时工”来执行这些任务了。于是会创建非核心线程去执行这个任务。注意，这一步需要获得全局锁。
4. 缓存队列满了， 且总线程数达到了maximumPoolSize，则会采取上面提到的拒绝策略进行处理。


首先去执行创建这个worker时就有的任务，当执行完这个任务后，worker的生命周期并没有结束，       
在while循环中，worker会不断地调用getTask方法从阻塞队列中获取任务然后调用task.run()执行任务,从而达到复用线程的目的。只要getTask方法不返回null,此线程就不会退出。

核心线程池中创建的线程想要拿到阻塞队列中的任务，先要判断线程池的状态，如果STOP或者TERMINATED，返回null
```    



#####  线程池 拒绝策略有哪些
RejectedExecutionHandler handler

拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为 ：

==ThreadPoolExecutor.AbortPolicy==：默认拒绝处理策略，丢弃任务并抛出RejectedExecutionException异常。

ThreadPoolExecutor.DiscardPolicy：丢弃新来的任务，但是不抛出异常。

ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列头部（最旧的）的任务，然后重新尝试执行程序（如果再次失败，重复此过程）。

ThreadPoolExecutor.CallerRunsPolicy：由调用线程(任务所属线程)处理该任务

#### 2.2.1 线程池 阻塞队列 （CLH） 原理
常用的几个阻塞队列：
```text
LinkedBlockingQueue

链式阻塞队列，底层数据结构是链表，默认大小是Integer.MAX_VALUE，也可以指定大小。

ArrayBlockingQueue

数组阻塞队列，底层数据结构是数组，需要指定队列的大小。

SynchronousQueue

同步队列，内部容量为0，每个put操作必须等待一个take操作，反之亦然。

DelayQueue

延迟队列，该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素
```

#### 2.2.2 各种锁接口 和实现类

#####  可重入锁和非可重入锁
重入锁的概念 ；        
这个锁支持一个线程对资源重复加锁。
```text
private volatile int state;  作为重入计数器
```
ReentrantLock 的中文意思就是可重入锁。

synchronized关键字就是使用的重入锁。        
在一个synchronized实例方法里面调用另一个本实例的synchronized实例方法，它可以重新进入这个锁，不会出现任何异常

##### ReentrantLock
内部有一个抽象类Sync，是继承了AQS,       
还有两个非抽象类NonfairSync和FairSync，它们都继承了Sync，都是独占式的排它锁

ReentrantLock支持非公平锁和公平锁两种。

##### 公平锁与非公平锁
公平锁 ： FIFO, 先对锁获取请求的线程先被满足，后对锁获取请求的线程后被满足

而非公平锁新入的线程则可以先尝试获取锁，如果失败了再排队。

非公平锁能提升一定的效率。但是非公平锁可能会发生线程饥饿（有一些线程长时间得不到锁）的情况

##### 读写锁和排它锁
排它锁 ：同一时刻只允许一个线程进行访问 , synchronized用的锁和ReentrantLock，其实都是“排它锁”

读写锁 ： 可以再同一时刻允许多个读线程访问。     
Java提供了 ReentrantReadWriteLock 类作为读写锁的默认实现，     
内部维护了两个锁：一个读锁，一个写锁。     
通过分离读锁和写锁，使得在“读多写少”的环境下，大大地提高了性能。

在写线程访问时，所有的读线程和其它写线程均被阻塞

##### StampedLock
StampedLock 的性能是非常优异的，基本上可以取代ReentrantReadWriteLock的作用。
      

#### 2.2.3 java 同步容器
ConcurrentMap、阻塞队列（BlockingQueue）、CopyOnWrite容器（CopyOnWritexxx）

#####  concurrentHashMap 原理
ConcurrentMap接口继承了Map接口

ConcurrentHashMap同HashMap一样也是基于散列表的map

由 Hash值数组 + Node链表结构组成（链表也会在长度达到8的时候转化为红黑树）。            
put数据时 以某个位置的头结点（链表的头结点或红黑树的root结点）为锁，配合自旋+CAS避免不必要的锁开销，进一步提升并发性能。

采用了分段锁，将数据分段，对每一段数据分配一把锁。       
当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。

有些方法需要跨段，比如size()、isEmpty()、containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，       
这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。

#####  copyOnWrite原理
写时复制，当我们往一个容器中添加元素的时候，不直接往容器中添加，而是将当前容器进行copy，复制出来一个新的容器，           
然后向新容器中添加我们需要的元素，      
最后将原容器的引用指向新容器。

“读操作”是没有加锁，直接读取

适合读多写少的场景，缺点是复制原容器会占用两倍内存，不能保证实时一致性，只能保证最终一致性


---

## 3 Mysql

### 3.1 sql优化的思路
优化索引的使用，减少全表扫描，减少回表次数

- 在 where条件字段，join 关联字段、order by 字段、建立索引
- 查询具体列名，不用select *
- 避免在查询列使用 函数
- 避免隐式转换

#### InnoDB有两大类索引：

聚集索引(clustered index)

普通索引(secondary index)

#### 回表
先定位主键值，再定位行记录，扫描两遍索引树，它的性能较扫一遍索引树更低。

#### 索引覆盖
只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快。

常见的方法是：将被查询的字段，建立到联合索引里去。

### 3.2 慢查询的处理方法
分析慢查询的执行计划，explain 查看 type 字段
```text
system > const > eq_ref > ref > range > index > ALL
```

如果 Extra字段为 Using index condition ，可以通过建立联合索引，优化为 Using index

### 3.3 [事务隔离级别](https://mp.weixin.qq.com/s/mZxAn7qRQ8EycVOcdql3hQ)

##### 读未提交 
可能出现脏读（读取到其他事务未提交的数据）、

不能重复读： 在同一事务中，同样的条件，第一次读的数据和第二次读的「数据不一样」。（因为中间有其他事务提交了修改）

幻读：在同一事务中，同样的条件，第一次和第二次读出来的「记录数不一样」。（因为中间有其他事务提交了插入/删除

##### 读已提交
可能出现 幻读、不可重复读

##### 可重复读（mysql innoDB 采用）
可能出现 幻读

##### 串行读
最严格的的隔离级别，并发效率低

```text
##### 脏读
A事务读取到B事务未提交的数据

##### 不可重复读 （行级锁可以处理这个问题）
A事务内相同条件多次读取，由于B事务修改或者删除数据，导致多次读取结果不一致

##### 幻读 (表级锁可以处理这个问题)
A事务内相同条件多次读取，由于B事务新增数据，导致多次读取结果不一致

```

#### 3.4 sql 使用
#### 对于join 和 left join ， on 和where的结果有没有区别 
使用内连接（inner join / join）时没有区别  

使用外连接（left join / right join）有区别

on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。   
```sql
select 
    dep.dept_no
    ,dep.emp_no
    ,sal.salary
    ,dep.from_date
    ,dep.to_date
from
    dept_manager dep
left join salaries sal
    on dep.emp_no = sal.emp_no
    and dep.to_date = '9999-01-01'
    and sal.to_date = '9999-01-01';	
```
 
where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。
```sql
-- 正确栗子
select 
    dep.dept_no
    ,dep.emp_no
    ,sal.salary
    ,dep.from_date
    ,dep.to_date
from
    dept_manager dep
left join salaries sal
    on dep.emp_no = sal.emp_no
where	
    dep.to_date = '9999-01-01'
    and sal.to_date = '9999-01-01';				
```

#### 3.5 InnoDB与MyISAM对比
![image](https://mmbiz.qpic.cn/mmbiz_png/ceNmtYOhbMQs4Ar4C7lr5CFmTkzO5qFP4ziaEN8O2vgic8ibP9RnGibTDcVaAxTKfTxeicpCrYquzWXRstmdviaCrSzA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


---



## 4 Spring

### 四种方式配置Bean
基于XML配置、注解配置、java类配置、Groovy DSL配置

### IOC
[Spring 如何解决循环依赖的问题](https://www.jianshu.com/p/8bb67ca11831)

[面试官：spring循环依赖是怎么解决的？](https://blog.csdn.net/hezuo1181/article/details/82831080)

#### 扫描注解定义的Bean
@Controller 、 @Service  、 @Repository 、@Component

#### 自动装配Bean
使用 @Autowired 默认按类型注入， 有多个相同类型时可以用 @Qualifier 指定Bean name

也可以使用 @Resource（按名称注入） 、 @Inject（按类型） 

可以对类成员、方法标注 @Autowired，

@Order 指定相同类型的Bean的加载顺序，值越小越优先

##### 延迟依赖注入
在class 和属性上同时标注 @lazy

#### Bean的作用范围、生命过程
默认作用范围是 singleton 单例， 可以使用 @Scope("prototype) 修改

在Bean实例化和属性注入完成后，执行 @PostConstruct 修饰的初始化方法

在容器关闭时，执行 @PreDestroy 修饰的方法

#### 基于Java 类的配置  @Configuration
@Configuration 本身标注了 @Component ，可以像普通Bean一样注入

普通的 POJO 只需要标注 @Configuration ，就可以为 Spring容器 提供bean定义       
每个标注了 @Bean的类型方法 相当于提供了一个Bean的定义信息
 
Spring会对配置类标注了 @Bean的方法进行 AOP增强

#### 使用基于 Java类的配置信息 启动Spring容器
通过 AnnotationConfigApplicationContext 的 register() 方法，      
然后调用 refresh() 方法

可以通过 @Import 注解 将多个配置类 组装到一个配置类

### 通过编码方式动态添加 Bean
#### 通过DefaultListableBeanFactory
 动态注入Bean，使Bean被AOP增强， 需要实现BeanFactoryPostProcessor#postProcessBeanFactory()，
 
### AOP的原理、应用
动态代理，JDK动态代理类继承了Proxy，所以JDK动态代理只能写成接口 （Java是单继承）

#### 4.2 Spring 事务
事务模板类 TransactionTemplate 配合 事务回调 TransactionCallback 指定具体的持久化操作

TransactionDefinition：Spring支持的事务属性

TransactionStatus：代表事务具体运行状态

PlatformTransactionManager：事务管理抽象接口，提交、回滚；      
不同的持久化框架有不同的实现类

重要的类 ： TransactionAspectSupport

##### 事务同步管理器
通过多个ThreadLocal变量保存线程不安全的事务相关的变量

##### ThreadLocal
保存线程本地化的容器，     
运行于多线程环境的某个对象使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程分配一个独立的变量副本

##### Spring事务的隔离级别？ 默认值？
TransactionDefinition :         
定义了与java.lang.sql同名的四个隔离级别，     
还有一个 默认的隔离级别表示使用底层数据库的默认隔离级别

##### Spring事务的传播属性？ 默认值？
默认值
```text
Propagation propagation() default Propagation.REQUIRED;
如果当前没有事务，新建一个事务，如果已经存在一个事务，加入到这个事务
```
7种类型的事务传播行为
```text
PROPAGATION_REQUIRED ：如果当前没有事务，新建一个事务，如果已经存在一个事务，加入到这个事务

PROPAGATION_SUPPORTS ：如果当前有事务，加入这个事务，否则以非事务方式运行

PROPAGATION_MANDATORY : 如果当前有事务，加入这个事务，否则抛出异常

PROPAGATION_REQUIRES_NEW ： 新建事务，挂起当前事务

PROPAGATION_NOT_SUPPORTED ：不允许事务，如果当前有事务，抛出异常

PROPAGATION_NEVER ：如果当前没有事务，新建一个事务，如果已经存在一个事务，新建一个事务保存点

PROPAGATION_NESTED： 使用嵌套事务时，底层数据源需要基于JDBC3.0，支持保存点
```

##### Spring事务的实现原理，嵌套事务的实现原理
通过AOP实现， Spring将事务管理的步骤 织入业务方法的连接点，     
比如获取线程绑定资源、开始事务、提交/回滚事务、异常处理

设置保存点，可以回滚到保存点

##### 回滚设置
运行期异常引发回滚，检查型异常不会引发回滚

##### @Transaction 应用位置
在方法上使用时，方法上的配置会覆盖类上的配置

##### spring 事务不生效(@Transactional注解无效)的场景
```text
1. 如果不是Innodb存储引擎，MyISAM不支持事务。

2. 没有指定rollbackFor参数默认只会捕获RuntimeException 和 E rror 来进行回滚。

3. 没有指定transactionManager参数，默认的transactionManager并不是我期望的，以及一个事务中涉及到了多个数据库。

4. 如果AOP使用了JDK动态代理，对象内部方法互相调用不会被Spring的AOP拦截，另外代理 public static 方法无效

5. 如果AOP使用了CGLIB代理，事务方法或者类不是public（private static final），无法被外部包访问到，或者是final无法继承，@transactional注解无效
```


---

## 5 Mybatis
- 自己怎么实现mybatis，实现原理
- mybatis 一二级缓存配置

---

## 6 Rabbit MQ

### Rabbit MQ 架构设计 
生产者、信道（交换器、绑定、队列）、消费者

集群模式，至少一个磁盘节点

### 如果 Rabbit MQ 挂掉了，后续流程怎么处理
搭建 Rabbit集群， Rabbit集群允许消费者和生产者在单个Rabbit MQ节点崩溃时 继续运行， 

如果集群中唯一的磁盘节点崩溃的话，集群仍然可以保持运行，但是无法更改任何东西      
可以在集群中设置多个磁盘节点

### 消息持久化
如果消息要从 MQ重启后恢复，消息必须
1. 投递模式选项设置为2 （持久）
2. 发送到持久化的交换器（durable 为 true）
3. 达到持久化的队列（durable 为 true）

MQ确保消息能从服务器重启中恢复的方式是 把消息写入磁盘上的一个持久化日志文件，        
当发送一条持久化消息到交换器，Rabbit MQ 会在消息保存到日志文件后发送响应

Rabbit MQ 会在消费者消费后把持久化消息标记为等待垃圾回收

在消费之前，如果 Rabbit MQ重启，Rabbit MQ会重播日志文件中的消息到对应的队列 或者交换器

持久化消息到磁盘会影响吞吐效率

### Rabbit MQ 如何保证消息正确投递
##### 1、生产者丢数据
RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。

transaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。

然而缺点就是吞吐量下降了，生产上用confirm模式的居多。
```text
一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)

一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)

这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。

相关接口 ：
org.springframework.amqp.core.AmqpTemplate#convertSendAndReceive(java.lang.String, java.lang.String, java.lang.Object, org.springframework.amqp.core.MessagePostProcessor)
```

##### 2、消息队列丢数据
开启持久化磁盘的配置，在消息持久化磁盘后，再给生产者发送一个Ack信号。
           
这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。
      
如何持久化呢，下面两步

1、将queue的持久化标识durable设置为true,则代表是一个持久的队列

2、发送消息的时候将deliveryMode=2

##### 3、消费者丢数据
消费者丢数据一般是因为采用了自动确认消息模式。

这种模式下，消费者会自动确认收到信息。这时rahbitMQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息。

至于解决方案，==采用手动确认消息即可==  autoDelete设置为false



### 如何保证消息不被重复消费？
这个问题其实换一种问法就是，如何保证消息队列的幂等性?

**正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除**

RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念

#### 造成重复消费的原因?
 就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者
 
#### 针对业务场景来答分以下几点

1、比如，你拿到这个消息做数据库的insert操作。

那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。

2、再比如，你拿到这个消息做redis的set的操作

那就容易了，不用解决。因为你无论set几次结果都是一样的，set操作本来就算幂等操作。

3、如果上面两种情况还不行，上大招。

准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录 

### 如何保证消息的顺序性？
通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(rabbitMq中就是queue)。        
然后只用一个消费者去消费该队列。

---


## 7 Redis
- redis 集群

### 持久化方案

#### 快照模式（RDB）
在写操作不是特别频繁，允许丢失部分数据的场景下，    
设置 每隔一段时间，达到一定写操作数量 ，进行自动保存，生成快照文件，或者进行手动保存
- save
- bgsave ： fork子进程保存快照

#### AOF（Append Only File） 模式
同步写选项、同步频率
- always        
    每个写命令都同步写入硬盘，会严重降低Redis 速度
- everysec      
    每秒执行一次同步，将多个写命令同步到硬盘
- no        
    让操作系统决定何时同步，不推荐

### 主从配置、哨兵模式，集群模式
==只有主服务器接受写命令==

#### 更换故障主服务器
##### 方法一：升级当前从服务器为主服务器

##### 方法二
1. 复制从服务器数据到新的机器，
2. 在新的机器上启动redis
3. 为从服务器指定新的主服务器

#### Redis复制过程  
SLAVEOF host port 设置当前服务器为 某台服务器的从服务器

1. 从服务器连接主服务器，发送SYNC命令
2. 主服务器执行 BGSAVE,在缓存区记录BGSAVE之后写入的命令，       
从服务器会根据配置选择清空自身数据，或向客户端返回错误

可以为从服务器指定新的从服务器，构成从服务器树

#### 哨兵模式 Redis Sentinel
目的是为了提供自动故障转移服务

配合Redis复制功能，Redis Sentinel是运行在特殊模式下的服务器     
它会监视一系列主服务器和对应的从服务器，        
==当主服务器失效时==，监视这个主服务器的所有Sentinel会基于彼此共有的信息选出一个新的主服务器，       
其他的从服务器会去复制这个新的主服务器

### 缓存雪崩和失效的场景
热点缓存key失效，大量请求直接访问数据库，导致数据库连接耗尽；
    
解决方案：
- 查询前参数合理性校验
- 设置不同的过期时间
- 在查询数据库数据之前再查一遍redis（双重检查），查询数据库之后，新建redis缓存，设置过期时间 
- 应对大规模查询（应对秒杀活动），将查询放入消息队列

---

## 8 SpringCloud 中间件

### 服务注册、服务发现

### 负载均衡、服务降级

---

## 9 Zookeeper

主节点失效，备份主节点需要通过选举，成为新的主节点，      
如果旧的主节点恢复，==如何避免存在两个主节点（脑裂）==

从节点如果失效，主节点应该能够检测到，不在继续派发任务给失效节点，       
重新派发未完成任务给其他节点，==如何避免重复消费==

主从节点 保持通信

#### 几个重要的 父znode
/workers  /assign     /tasks

### zookeeper 实现分布式锁
一个线程尝试创建 临时节点 /lock, (临时节点会在会话过期 或关闭时 自动被删除) 
```text
create -e /lock ""
```
其他线程因为节点存在，无法创建/lock   
监听到 /lock 删除时，再次尝试创建 /lock，如果其他线程创建 /lock 成功，继续监听 /lock

#### 在主节点上增加监视点
```text
stat /master true
```

#### 设置 子节点的监视点
```text
ls /workers true
```

---

## 10 性能优化
#### 如果一个 前端请求查询耗时很长，怎么优化
- 查看nginx日志，是否是网络问题
- top命令查看 服务器内存 、IO情况，
- 查看服务日志，是否代码逻辑不合理，是否有多线程锁竞争
- 开启慢查询，是否有较慢的sql，能否优化查询，优化索引
- 热点数据是够可以缓存
![image](https://img-blog.csdnimg.cn/20190111141308700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdhZGFt,size_16,color_FFFFFF,t_70)
- 第三方接口调用超时


- 线上内存溢出的场景和处理方法
    - top定位查看服务器状态，获取占用内存多的进程ID，保存线程栈信息，
    - 下载dump文件，分析 dump文件

- zookeeper / eureka 配置本地调用公共服务

## 其他

#### 从1000w个数字中找出最小的10个并打印
advance.sort.HeapSort.findMinTopK

---

- [记一次蚂蚁金服的面试经历](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485070&idx=1&sn=31894a1bdda357d897962a9fc3a994b7&chksm=cea24945f9d5c0531db568321f1d8d7a4e848e04aa2df18e589db9ba4aafee0fb0cebb965252&token=463285003&lang=zh_CN&scene=21#wechat_redirect)

https://www.bilibili.com/read/cv5554230?share_medium=android&share_source=weixin&bbid=87E1A2EB-DC6F-4726-A9A5-51D5A927762310277infoc&ts=1586753871769