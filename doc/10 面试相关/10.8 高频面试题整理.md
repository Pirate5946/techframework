## 自我介绍
我叫刘涛，2015年毕业后主要从事ETL、报表开发、图表可视化展现相关的工作，     
参与了湖南农村信用社的 财务报表系统后期的一些开发、维护工作

2016年底作为4人开发小组的组长，主导了北京中关村银行 企业报表系统的 部署开发上线全流程，
从前期项目环境搭建，需求讨论，到项目开发、流程调试，
上线前项目文档验收 自己都参与了其中

2018年 参与了一个CRM项目，
作为PAAS平台的元数据服务小组成员，主要负责元数据服务的原有功能维护 和
新业务功能的扩展，包括对公司其他业务线和公司的合作伙伴提供rest接口，

另外也有配合中间件小组 对元数据服务进行一些技术栈升级， 
比如替换ID生成器，替换消息队列（kestrel转rabbit MQ）

2019年全年参与了一个机票代理平台的4.0版本迭代，项目于2020年元旦成功上线     
自己作为项目核心开发成员，主要负责订单服务，政策服务，基础数据服务的后端功能开发    
和部分前台页面开发，

对于微服务环境部署、服务拆分工作也有涉及

希望接下来继续从事Java服务端开发的工作

## 项目中遇到的难点
#### 1. 多人同时维护基础数据时（改的不是同一项数据，后提交的修改覆盖 前面的修改），post请求 需要保证幂等性，同时记录数据变动日志
1. 拦截修改前的查询请求，根据请求生成页面版本号，在redis中缓存版本号和实体信息           
2. 拦截修改请求，比对版本号，通过后比较实体修改前后的信息，记录操作日志
3. 通过消息队列 解耦日志服务的后续操作 （新旧实体比较 和入库）

#### 2. 在一个服务中配置两个数据源 
1. AOP拦截指定请求，通过ThreadLocal 设置当前线程数据源

2. 继承 AbstractRoutingDataSource 重写 determineCurrentLookupKey 方法 获取当前线程数据源 


## 0 基础
### 1、java的object方法有哪些
- hashcode、equals
- getClass
- toString
- notify、notifyAll
- wait
- clone
- finalize


### 2. 哪些场景下，子类需要重写 equals 方法和 hashCode 方法？     
Object的equals只比较了对象的引用地址，重写equals()是为了实现自己的区分逻辑，

==如果重写的equals()方法确定了两个对象相等，则这两个对象的hashCode必须返回相同的值==
，Object的hashCode是一个native本地方法，所以必须重写    

重写hashCode()是为了提高hash tables的使用效率，  
如果equals()方法确定了两个对象不相等，这个两个对象的hashCode还是有可能相等的。     
但是不同的对象应该有着不同的hashCode，这样可以提高hash tables的使用效率。

对于equals不相同而hashCode相同的元素集合，在哈希表中会以链表或者红黑树的形式储存

### 3. 列表中学生按照年龄排序      
重写compareTo
```java
Collections.sort(list, new Comparator<User>() {
   @Override
   public int compare(User o1, User o2) {
       // 升序 
       return o1.getAge().compareTo(o2.getAge());
       // 降序
       // return o2.getAge().compareTo(o1.getAge());
   }
});
```

### static 关键字使用场景，作用
只存在一份引用，放在方法区，所有线程共享

---

## 1 Java 集合

### 1.1 List 
支持按索引访问，存入和取出顺序不变，元素可重复，可以保存null值   

#### ArrayList 底层数据结构
Object数组，

#### add 方法逻辑
1、 检查是否需要扩容     
新的长度不长于 MAX_ARRAY_SIZE 时，增长为原长度的1.5倍，否则赋值为 MAX_ARRAY_SIZE
```text
int newCapacity = oldCapacity + (oldCapacity >> 1);

elementData = Arrays.copyOf(elementData, newCapacity);
```
2、 在末尾添加元素
```java
elementData[size++] = e;
```

####  for/foreach 循环删除list中 满足条件的对象Java 有没有问题？
有问题，快速失败机制，会抛出异常 [ConcurrentModificationException的原因以及解决措施](https://my.oschina.net/hosee/blog/612718)

单线程解决方案：使用 迭代器的remove方法

多线程 两种解决方案：     
1. 在使用iterator迭代的时候使用synchronized或者Lock进行同步；（一个个迭代就和单线程一样了）

2. 使用并发容器CopyOnWriteArrayList代替ArrayList和Vector。

#### LinkedList
双向列表，增删快

##### add 方法
```java
void linkLast(E e) {
    final Node<E> l = last;
    final Node<E> newNode = new Node<>(l, e, null);
    last = newNode;
    if (l == null)
        first = newNode;
    else
        l.next = newNode;
    size++;
    modCount++;
}
```

### ArrayList和LinkedList的区别
数据结构不同，使用场景不同

### 在jvm层面，数组和链表有什么区别
不太清除

### HashSet 、
内部持有 HashMap引用， key 可以为 null, 不能重复

### HashMap

### hashMap的实现原理，链表是头插法还是尾插法
1.8 之前是头插法、1.8是尾插法

#### 底层数据结构
数组 + 链表 （长度超过 8 转换成红黑树）

#### put 方法流程
1、 初始化第一次调用 put，    
根据初始化给的初始容量（会向上调整为2的n次幂），初始化 hash表（Node<K,V>[] table）

2、 根据 key的 hash值取模，获取key在 hash表（Node数组）中的存放位置，   
取模方法：
```java
(n - 1) & hash
```

如果当前索引位置没有值，在当前位置初始化 Node     

如果当前索引位置有值（hash冲突），     
   - 如果是重复的key，用新值替换旧值，返回旧值
```java
if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))
```
   - 遍历查看当前节点的下一节点，直到找到重复的key，用新值替换旧值，返回旧值；     
   或者找到null节点，在当前位置初始化 Node，        
   如果链表的长度 >= 8 并且hash表长度大于64，将当前列表转换成红黑树，否则reHash()     
   

3、 modCount 记录修改次数 
```java
transient int modCount;
```

4、 当前 Node数量自增1 ，与当前阈值比较，判断是否需要扩容

#### jdk8怎么优化hashmap扩容导致的死循环问题
JDK7 线程扩容时的搬运结点操作 为了提高效率采用的头插法 导致线程之间 看到了错误的next指向，导致成环，       

JDK8采用尾插法（尾插法一是用于避免死循环，二是根据槽中个数判断是否需要树化）修复了此问题，但是由于是线程不安全的，还会有别的并发问题发生


#### HashMap 和 HashTable 区别？

##### 1. 数据结构     
HashTable : 数组 + 链表

HashMap ： 数组 + 链表 （长度超过 8 转换成红黑树）

Hashtable中，key和value都不允许出现null值。        

在HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null，     
在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用 containsKey()方法来判断。

##### 2. 线程安全性
HashTable : 线程安全 ， Synchronized 修饰方法，当前实例被锁住，只能串行调用其他方法

HashMap ： 线程不安全

### 为啥会线程不安全？ 如何才能得到一个线程安全的HashMap？
Java7在多线程操作HashMap时可能引起死循环，原因是扩容转移后前后链表顺序倒置，在转移过程中修改了原来链表中节点的引用关系。

Java8在同样的前提下并不会引起死循环，原因是扩容转移后前后链表顺序不变，保持之前节点的引用关系。

put/get方法都没有加同步锁，多线程情况最容易出现的就是：     
无法保证上一秒put的值，下一秒get的时候还是原值，所以线程安全还是无法保证。

使用 ConcurrentHashMap、 或者 Collections.synchronizedMap()

### 在数据结构上，栈和队列有什么区别
队列是先进先出，新来的成员总是加入队尾

栈是先进后出，继承了Vector，线程安全，栈只能从顶部取数据


---

## select epoll,poll的区别
select，poll，epoll都是IO多路复用的机制，

IO多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作

#### select
不停的调用poll,直到有需要的消息为止，最大连接数 1024

#### poll
没有连接上限

select, poll是为了解決同时大量IO的情況（尤其网络服务器），但是随着连接数越多，性能越差

epoll是select和poll的改进方案，在 linux 上可以取代 select 和 poll，可以处理大量连接的性能问题


## 2 Java并发相关
定义： 多个线程读写 可变的共享资源 时，跟单个线程操作结果一致

### sleep()和wait()的区别

1. wait可以指定时间，也可以不指定；而sleep必须指定时间。
2. wait释放cpu资源，同时释放锁；sleep释放cpu资源，但是不释放锁，所以易死锁。
3. wait必须放在同步块或同步方法中，而sleep可以在任意位置


### 2.1 原理篇

#### 比较一下 volatile 和 Synchronized
volatile 修饰变量，可以保证 线程之间共享资源 的 可见性、有序性

Synchronized 可以修改代码块，方法，类 ；可以保证 被它修饰的方法或者代码块在任意时刻只能有一个线程执行

#### volatile是什么，实现原理，可以实现原子性吗 ,线程安全吗，通过什么机制实现锁？
volatile是通过编译器在生成字节码时，在指令序列中添加“内存屏障”来禁止指令重排序

在Java多线程情况下，volatile修饰的变量可以保证线程可见性且提供了一定的有序性，不能保证原子性，

不能保证线程安全，比如 i++

通过CAS机制实现线程安全，在Java中Unsafe对CAS进行了封装

#### synchronized 是公平锁吗，
非公平锁， synchronized 获取不到锁的时候，会自动加入队列，等待线程释放锁后所有等待的线程同时去竞争
     
可重入

悲观锁

#### 实现锁的原理，获取对象的monitor 属于对象什么信息
同步代码块是使用 monitorenter 和 monitorexit 指令实现的

synchronized方法，在Class文件的方法表中将该方法的accessflags字段中的synchronized标志位置1

Java的锁都是基于对象的，对象的“锁”的信息是存放在对象头的Mark Word

Java 6 为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁“

当对象状态为偏向锁时，Mark Word存储的是偏向的线程ID；        
当状态为轻量级锁时，Mark Word存储的是指向线程栈中Lock Record的指针；        
当状态为重量级锁时，Mark Word为指向堆中的monitor对象的指针

#### 自旋
所谓自旋锁，就是让该线程等待一段时间，不会被立即挂起（就是不让前来获取该锁（已被占用）的线程立即阻塞），看持有锁的线程是否会很快释放锁。

怎么等待呢？

执行一段无意义的循环即可（自旋）

避免CPU从用户态转为核心态，频繁的阻塞和唤醒

JDK 1.6引入了更加聪明的自旋锁，即自适应自旋锁，线程如果自旋成功了，那么下次自旋的次数会更加多

## JVM
### 1. 怎么判断一个对象可以被回收
可达性分析 ： 从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链时，则认为此对象可以被回收

### 2. 哪些对象可以作为GC Root
方法区、栈和本地方法区不被GC所管理,因而选择这些区域内的对象作为GC roots,

a.虚拟机栈(栈桢中的本地变量表)中的引用的对象        
b.方法区中的类静态属性引用的对象       
c.方法区中的常量引用的对象      
d.本地方法栈中JNI的引用的对象       

### 3. 垃圾回收器，G1有什么优势
G1的设计原则就是简单可行的性能调优，

主要应用在多CPU大内存的服务中，在满足高吞吐量的同时，尽可能的满足垃圾回收时的暂停时间

分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念

G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内。

### 4. jvm启动进程配置哪些参数
 nohup java -server -Duser.timezone=GMT+08 -Xmx1g -Xms1g 
 -XX:NewRatio=4 -XX:SurvivorRatio=8 
 -XX:PermSize=64m -XX:MaxPermSize=128m -Xss512k 
 -XX:ThreadStackSize=128k -XX:MaxDirectMemorySize=256m 
 -XX:-ReduceInitialCardMarks -XX:+PrintGCDetails 
 -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -Xloggc:/LOGS/applogs/jvm-log/web-gc.log 
 -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled 
 -XX:ParallelCMSThreads=4 -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection 
 -XX:CMSInitiatingOccupancyFraction=50 -XX:CMSFullGCsBeforeCompaction=2 -XX:+UseCompressedOops 
 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/LOGS/applogs/jvm-dump/web_heapDump.hprof  
 -Dcom.sun.management.jmxremote=true -Djava.rmi.server.hostname=192.168.1.221 
 -Dcom.sun.management.jmxremote.port=28081 -Dcom.sun.management.jmxremote.ssl=false 
 -Dcom.sun.management.jmxremote.authenticate=false -XX:+UnlockCommercialFeatures -XX:+FlightRecorder 
 -jar bs4-web-0.0.1-SNAPSHOT.jar >>/LOGS/applogs/bs4-web.log 2>&1 &

### 5. 你们jvm垃圾回收新生代、老年代怎么配置的，为什么这样配置
-XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆内存的1/5

1.追求响应时间优先

这种需求下，新生代尽可能设置大一些，因为新生代比较大，发生垃圾回收的频率会比较低，响应时间快速。

老年代空间不足发生Full GC

### 6. 堆内存4G，老年代分2.5个G,gc时间是多长
不知道

### jvm一次完整的GC流程
当 Eden 区没有足够空间时，会发起一次 Minor GC；清理不可达的对象

存活的对象，年龄+1，一定次数后进入老年代，老年代空间不够时，进行full gc，Full GC 尽量避免

### 栈内存溢出的情形（StackOverflowError)，如何解决
1、递归调用层次太多。递归函数在运行时会执行压栈操作，当压栈次数太多时，也会导致堆栈溢出。

2、方法内声明了海量的局部变量，局部数组过大。当函数内部的数组过大时，有可能导致堆栈溢出。

解决方案：
1. 修复引发无限递归调用的异常代码,        

2. 通过 JVM 启动参数 -Xss 增加线程栈内存空间， 某些正常使用场景需要执行大量方法或包含大量局部变量，这时可以适当地提高线程栈空间限制

### 线上oom怎么排查
查看日志、分析dump文件，查看占用内存较多的对象

1. ps -aux|grep java 当服务重新部署后，可以找出当前Java进程的PID

2. jstat -gcutil pid interval 用于查看当前GC的状态,它对Java应用程序的资源和性能进行实时的命令行的监控，包括了对Heap size和垃圾回收状况的监控

3. jmap -histo:live pid 可用统计存活对象的分布情况，从高到低查看占据内存最多的对象。上图

4. 分析dump文件

---


### 2.2 JDK 工具篇

#### [2.2.0 线程池](http://concurrent.redspider.group/article/03/12.html)
线程池顶层接口是Executor接口，ThreadPoolExecutor 是这个接口的实现类

##### 线程池原理
使用线程池主要有以下三个原因：

- 控制并发的数量。并发数量过多，可能会导致资源消耗过多，从而造成服务器崩溃。（主要原因）
- 创建/销毁线程需要消耗系统资源，线程池可以复用已创建的线程。
- 可以对线程做统一管理 (传入 ThreadFactory ，设置线程池名称 、线程优先级、是否为守护线程)

ThreadPoolExecutor在创建线程时，会将线程封装成工作线程worker,并放入工作线程组中，       
然后这个worker反复从阻塞队列中拿任务去执行。

##### 线程池构造函数的参数，默认值
涉及到5~7个参数，必须的5个参数

```text
int corePoolSize：该线程池中核心线程数最大值

    核心线程：线程池中有两类线程，核心线程和非核心线程。核心线程默认情况下会一直存在于线程池中，即使这个核心线程什么都不干（铁饭碗），而非核心线程如果长时间的闲置，就会被销毁（临时工）。

int maximumPoolSize：该线程池中线程总数最大值 。

    该值等于核心线程数量 + 非核心线程数量。

long keepAliveTime：非核心线程闲置超时时长。

    非核心线程如果处于闲置状态超过该值，就会被销毁。如果设置allowCoreThreadTimeOut(true)，则会也作用于核心线程。

TimeUnit unit：keepAliveTime的单位。

    TimeUnit是一个枚举类型 ，包括以下属性：
    
    NANOSECONDS ： 1微毫秒 = 1微秒 / 1000 MICROSECONDS ： 1微秒 = 1毫秒 / 1000 MILLISECONDS ： 1毫秒 = 1秒 /1000 SECONDS ： 秒 MINUTES ： 分 HOURS ： 小时 DAYS ： 天
    
BlockingQueue workQueue：阻塞队列，维护着等待执行的Runnable任务对象。

    常用的几个阻塞队列：
    
    LinkedBlockingQueue
    
    链式阻塞队列，底层数据结构是链表，默认大小是Integer.MAX_VALUE，也可以指定大小。
    
    ArrayBlockingQueue
    
    数组阻塞队列，底层数据结构是数组，需要指定队列的大小。
    
    SynchronousQueue
    
    同步队列，内部容量为0，每个put操作必须等待一个take操作，反之亦然。
    
    DelayQueue
    
    延迟队列，该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 
```

两个非必须的参数。
```text
ThreadFactory threadFactory

    创建线程的工厂 ，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂     

RejectedExecutionHandler handler

    拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为 ：
```

##### 总结一下处理流程
```text
1. 线程总数量 < corePoolSize，无论线程是否空闲，都会新建一个核心线程执行任务（让核心线程数量快速达到corePoolSize，在核心线程数量 < corePoolSize时）。注意，这一步需要获得全局锁。
2. 线程总数量 >= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了线程复用）。
3. 当缓存队列满了，说明这个时候任务已经多到爆棚，需要一些“临时工”来执行这些任务了。于是会创建非核心线程去执行这个任务。注意，这一步需要获得全局锁。
4. 缓存队列满了， 且总线程数达到了maximumPoolSize，则会采取上面提到的拒绝策略进行处理。


首先去执行创建这个worker时就有的任务，当执行完这个任务后，worker的生命周期并没有结束，       
在while循环中，worker会不断地调用getTask方法从阻塞队列中获取任务然后调用task.run()执行任务,从而达到复用线程的目的。只要getTask方法不返回null,此线程就不会退出。

核心线程池中创建的线程想要拿到阻塞队列中的任务，先要判断线程池的状态，如果STOP或者TERMINATED，返回null
```    

##### prestartAllCoreThreads 启动所有核心线程

#####  线程池 拒绝策略有哪些
RejectedExecutionHandler handler

拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为 ：

==ThreadPoolExecutor.AbortPolicy==：默认拒绝处理策略，丢弃任务并抛出RejectedExecutionException异常。

ThreadPoolExecutor.DiscardPolicy：丢弃新来的任务，但是不抛出异常。

ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列头部（最旧的）的任务，然后重新尝试执行程序（如果再次失败，重复此过程）。

ThreadPoolExecutor.CallerRunsPolicy：由调用线程(任务所属线程)处理该任务

#### 2.2.1 线程池 阻塞队列 （CLH） 原理
常用的几个阻塞队列：
```text
LinkedBlockingQueue

链式阻塞队列，底层数据结构是链表，默认大小是Integer.MAX_VALUE，也可以指定大小。

ArrayBlockingQueue

数组阻塞队列，底层数据结构是数组，需要指定队列的大小。

SynchronousQueue

同步队列，内部容量为0，每个put操作必须等待一个take操作，反之亦然。

DelayQueue

延迟队列，该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素
```

#### 2.2.2 各种锁接口 和实现类

#####  可重入锁和非可重入锁
重入锁的概念 ；        

支持同一个线程对资源重复加锁。
```text
private volatile int state;  作为重入计数器
```
ReentrantLock 的中文意思就是可重入锁。

synchronized关键字就是使用的重入锁。        
在一个synchronized实例方法里面调用另一个本实例的synchronized实例方法，它可以重新进入这个锁，不会出现任何异常

##### ReentrantLock
内部有一个抽象类Sync，是继承了AQS,       
还有两个非抽象类NonfairSync和FairSync，它们都继承了Sync，都是独占式的排它锁

ReentrantLock支持非公平锁和公平锁两种。

##### 公平锁与非公平锁
公平锁 ： FIFO, 先对锁获取请求的线程先被满足，后对锁获取请求的线程后被满足

而非公平锁新入的线程则可以先尝试获取锁，如果失败了再排队。

非公平锁能提升一定的效率。但是非公平锁可能会发生线程饥饿（有一些线程长时间得不到锁）的情况

##### 读写锁和排它锁
排它锁 ：同一时刻只允许一个线程进行访问 , synchronized用的锁和ReentrantLock，其实都是“排它锁”

读写锁 ： 可以再同一时刻允许多个读线程访问。     
Java提供了 ReentrantReadWriteLock 类作为读写锁的默认实现，     
内部维护了两个锁：一个读锁，一个写锁。     
通过分离读锁和写锁，使得在“读多写少”的环境下，大大地提高了性能。

在写线程访问时，所有的读线程和其它写线程均被阻塞

##### StampedLock
JDK1.8 的StampedLock 的性能是非常优异的，基本上可以取代ReentrantReadWriteLock的作用。
      

#### 2.2.3 java 同步容器、线程安全的集合
ConcurrentMap、阻塞队列（BlockingQueue）、CopyOnWrite容器（CopyOnWriteArrayList、 CopyOnWriteArraySet）

#####  concurrentHashMap 原理
ConcurrentMap接口继承了Map接口

ConcurrentHashMap同HashMap一样也是基于散列表的map

由 Hash值数组 + Node链表结构组成（链表也会在长度达到8的时候转化为红黑树）。            
put数据时 以某个位置的头结点（链表的头结点或红黑树的root结点）为锁，配合自旋+CAS避免不必要的锁开销，进一步提升并发性能。

采用了分段锁，将数据分段，对每一段数据分配一把锁。       
当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。

有些方法需要跨段，比如 size()、isEmpty()、containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，       
这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。

##### ConcurrentHashMap 1.7和1.8的区别、jdk8对 ConcurrentHashMap 做了哪些优化
1. 将原先table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构， 避免链表过长

2. 采用了分段锁，以某个位置的头结点（链表的头结点或红黑树的root结点）为锁，       
当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。

##### concurrentHashMap 怎么实现线程安全，分段锁是jdk几提出的
JDK1.8提出分段锁，put时, synchronized 将Node链表的头节点作为锁，

在初始化数组时使用了 volatile + CAS + 自旋 操作 决定到底是哪个线程有资格进行初始化，其他线程均只能等待

#####  copyOnWrite原理
写时复制，当我们往一个容器中添加元素的时候，不直接往容器中添加，而是将当前容器进行copy，复制出来一个新的容器，           
然后向新容器中添加我们需要的元素，      
最后将原容器的引用指向新容器。

“读操作”是没有加锁，直接读取

适合读多写少的场景，缺点是复制原容器会占用两倍内存，不能保证实时一致性，只能保证最终一致性

#### AtomicInteger 原子类的原理、AtomicInteger 怎么实现原子性
volatile 修改 int值， 底层通过 Unsafe类的 CAS操作尝试更新值

####  CAS实现原子操作的三大问题

##### 10.5.1 ABA问题
      所谓ABA问题，就是一个值原来是A，变成了B，又变回了A。这个时候使用CAS是检查不出变化的，但实际上却被更新了两次。
      
      ABA问题的解决思路是在变量前面追加上版本号或者时间戳。      
      从JDK 1.5开始，JDK的atomic包里提供了一个类AtomicStampedReference类来解决ABA问题。     
      
##### 10.5.2 循环时间长开销大
      CAS多与自旋结合。如果自旋CAS长时间不成功，会占用大量的CPU资源。
      
      解决思路是让JVM支持处理器提供的pause指令。
      
      pause指令能让自旋失败时cpu睡眠一小段时间再继续自旋，从而使得读操作的频率低很多,为解决内存顺序冲突而导致的CPU流水线重排的代价也会小很多。      
      
##### 10.5.3 只能保证一个共享变量的原子操作
      这个问题你可能已经知道怎么解决了。有两种解决方案：
      
      使用JDK 1.5开始就提供的AtomicReference类保证对象之间的原子性，把多个变量放到一个对象里面进行CAS操作；
      使用 synchronize 锁。锁内的临界区代码可以保证只有当前线程能操作      


---


## 3 Mysql

### 3.1 sql优化的思路
优化索引的使用，减少全表扫描，减少回表次数

- 在 where条件字段，join 关联字段、order by 字段、建立索引
- 查询具体列名，不用select *
- 避免在查询列使用 函数
- 避免隐式转换
- 如果出现OR的一个条件没有索引时，建议使用 union 或建立联合索引
- 延迟关联，先通过查询条件查询主键值，然后关联查询目标字段
- 尝试用表关联代替嵌套子查询

#### InnoDB有两大类索引：

聚集索引(clustered index)

普通索引(secondary index)

#### 聚簇索引（clustered index）与非聚簇索引（secondary index）的区别 ？
1、聚簇索引（clustered index)     
a) 一个索引项直接对应实际数据记录的存储页，可谓“直达”，行数据就储存在索引树的叶子节点上
b) 主键缺省使用它
c) 索引项的排序和数据行的存储排序完全一致，利用这一点，想修改数据的存储顺序，可以通过改变主键的方法（撤销原有主键，另找也能满足主键要求的一个字段或一组字段，重建主键）
d) 一个表只能有一个聚簇索引（理由：数据一旦存储，顺序只能有一种）

2、非聚簇索引（secondary index）     
a) 索引叶子节点存储的不再是行的物理位置，而是主键值，辅助索引访问数据总是需要二次查找
b) 一个表可以有多个非聚簇索引

#### 回表
先定位主键值，再定位行记录，扫描两遍索引树，它的性能较扫一遍索引树更低。

#### 索引覆盖
只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快。

常见的方法是：将被查询的字段，建立到联合索引里去。

### 3.2 慢查询的处理方法、关注的字段（type、key、extra）
分析慢查询的执行计划，explain 查看 type 字段
```text
system > const > eq_ref > ref > range > index > ALL
```
key列显示索引实际决定使用的键，没有使用索引时 值为null

如果 Extra字段为 Using index condition ，可以通过建立联合索引，优化为 Using index


### 3.3 [事务隔离级别](https://mp.weixin.qq.com/s/mZxAn7qRQ8EycVOcdql3hQ)

##### 读未提交 
可能出现脏读（读取到其他事务未提交的数据）、

不能重复读： 在同一事务中，同样的条件，第一次读的数据和第二次读的「数据不一样」。（因为中间有其他事务提交了修改）

幻读：在同一事务中，同样的条件，第一次和第二次读出来的「记录数不一样」。（因为中间有其他事务提交了插入/删除）

##### 读已提交
可能出现 幻读、不可重复读

##### 可重复读（mysql innoDB 采用）
可能出现 幻读

##### 串行读
最严格的的隔离级别，并发效率低

```text
##### 脏读
A事务读取到B事务未提交的数据

##### 不可重复读 （行级锁可以处理这个问题）
A事务内相同条件多次读取，由于B事务修改或者删除数据，导致多次读取结果值不一致

##### 幻读 (表级锁可以处理这个问题)
A事务内相同条件多次读取，由于B事务新增数据，导致多次读取结果总数不一致

```

#### 3.4 sql 使用
#### 对于join 和 left join ， on 和where的结果有没有区别 
使用内连接（inner join / join）时没有区别  

##### 使用外连接（left join / right join）有区别

on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。   
```sql
select 
    dep.dept_no
    ,dep.emp_no
    ,sal.salary
    ,dep.from_date
    ,dep.to_date
from
    dept_manager dep
left join salaries sal
    on dep.emp_no = sal.emp_no
    and dep.to_date = '9999-01-01'
    and sal.to_date = '9999-01-01';	
```
 
where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。
```sql
-- 正确栗子
select 
    dep.dept_no
    ,dep.emp_no
    ,sal.salary
    ,dep.from_date
    ,dep.to_date
from
    dept_manager dep
left join salaries sal
    on dep.emp_no = sal.emp_no
where	
    dep.to_date = '9999-01-01'
    and sal.to_date = '9999-01-01';				
```

#### 3.5 InnoDB与MyISAM对比
![image](https://mmbiz.qpic.cn/mmbiz_png/ceNmtYOhbMQs4Ar4C7lr5CFmTkzO5qFP4ziaEN8O2vgic8ibP9RnGibTDcVaAxTKfTxeicpCrYquzWXRstmdviaCrSzA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### innoDB怎么实现的ACID特性 、 Atomicity(原子性),Consistency(一致性),Isolation(隔离性),Transaction(持久性)
通过事务控制，事务的本质就是锁和并发和重做日志的结合体

redo日志记录了数据变化的每一个动作，数据库锁保证了事务的隔离性，持有锁的事务才能修改数据

### innoDB支持几种锁
一种是行级锁，一种是意向锁（表级别的锁）

- 意向共享锁（读锁 IS Lock），事务想要获取一张表的几行数据的共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
- 意向排他锁（写锁 IX Lock），事务想要获取一张表中几行数据的排它锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

### innoDB的标准行级锁有哪两种
共享锁（读锁 S Lock），允许事务读一行数据        
排它锁（写锁 X Lock），允许事务删除一行数据或者更新一行数据

### B+树叶子节点存的是什么
主键KEY或者具体行数据

---



## 4 Spring

### spring 和 spring boot的区别
1. 内嵌了如Tomcat，Jetty这样的容器，也就是说可以直接跑起来，用不着再做部署工作了。

2. 无需再像Spring那样搞一堆繁琐的xml文件的配置

3. 整合常用依赖，提供的POM可以简化Maven的配置。当我们引入核心依赖时，SpringBoot会自动引入其他依赖

### 四种方式配置Bean
基于XML配置、注解配置、java类配置、Groovy DSL配置

### IOC
[Spring 如何解决循环依赖的问题](https://www.jianshu.com/p/8bb67ca11831)

[面试官：spring循环依赖是怎么解决的？](https://blog.csdn.net/hezuo1181/article/details/82831080)

#### FactoryBean 和 BeanFactory 的区别？ FactoryBean和普通Bean的区别
BeanFactory 是Spring框架的底层核心接口，通过众多实现类完成 Bean的创建和管理，BeanFactory会缓存Bean实例

FactoryBean是一个工厂类接口，通过实现该接口可以自定义Bean的实例化逻辑（通过getObject()方法），用来实例化一些复杂的Bean ，     
例如Mybatis的SqlSessionFactoryBean

#### 扫描注解定义的Bean
@Controller 、 @Service  、 @Repository 、@Component

#### 自动装配Bean
使用 @Autowired 默认按类型注入， 有多个相同类型时可以用 @Qualifier 指定Bean name

也可以使用 @Resource（按名称注入） 、 @Inject（按类型） 

可以对类成员、方法标注 @Autowired，

@Order 指定相同类型的Bean的加载顺序，值越小越优先

##### 延迟依赖注入
在class 和属性上同时标注 @lazy

#### Bean的作用范围、生命过程
默认作用范围是 singleton 单例， 可以使用 @Scope("prototype) 修改

在Bean实例化和属性注入完成后，执行 @PostConstruct 修饰的初始化方法

在容器关闭时，执行 @PreDestroy 修饰的方法

#### 基于Java 类的配置  @Configuration
@Configuration 本身标注了 @Component ，可以像普通Bean一样注入

普通的 POJO 只需要标注 @Configuration ，就可以为 Spring容器 提供bean定义       
每个标注了 @Bean的类型方法 相当于提供了一个Bean的定义信息
 
Spring会对配置类标注了 @Bean的方法进行 Bean的实例化

#### 使用基于 Java类的配置信息 启动Spring容器
通过 AnnotationConfigApplicationContext 的 register() 方法，      
然后调用 refresh() 方法

可以通过 @Import 注解 将多个配置类 组装到一个配置类

### 通过编码方式动态添加 Bean
#### 通过DefaultListableBeanFactory
 动态注入Bean，使Bean被AOP增强， 需要实现BeanFactoryPostProcessor#postProcessBeanFactory()，
 
### AOP的原理、应用
动态代理，通过定义切面和增强，完成目标方法的增强       
1. JDK动态代理，运行期完成，需要目标类实现接口，并且被拦截的方法在接口中有定义，通过反射生成接口的实现类，     
生成快，运行效率低，适合非单例的Bean

2. cglib代理 ，运行期完成，动态创建子类，不能代理final、private方法，不需要目标类实现接口，生成慢，运行效率高，适合单例缓存池的Bean生成

### Spring如何选择两种代理模式的？
    
    1、如果目标对象实现了接口，则默认采用JDK动态代理；
    
    2、如果目标对象没有实现接口，则使用Cglib代理；
    
    3、如果目标对象实现了接口，但强制使用了Cglib，则使用Cglib进行代理

#### 4.2 Spring 事务
事务模板类 TransactionTemplate 配合 事务回调 TransactionCallback 指定具体的持久化操作

TransactionDefinition：Spring支持的事务属性

TransactionStatus：代表事务具体运行状态

PlatformTransactionManager：事务管理抽象接口，提交、回滚；      
不同的持久化框架有不同的实现类

重要的类 ： TransactionAspectSupport

##### 事务同步管理器
通过多个ThreadLocal变量保存线程不安全的事务相关的变量

##### Spring事务的实现原理，嵌套事务的实现原理
通过AOP实现， Spring将事务管理的步骤 织入业务方法的连接点，     
比如获取线程绑定资源、开始事务、提交/回滚事务、异常处理

通过多个ThreadLocal变量保存线程不安全的事务相关的变量

设置保存点，可以回滚到保存点

##### 回滚设置
运行期异常引发回滚，检查型异常不会引发回滚

##### @Transaction 应用位置
在方法上使用时，方法上的配置会覆盖类上的配置

##### ThreadLocal
保存线程本地化的容器，     
运行于多线程环境的某个对象使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程分配一个独立的变量副本

##### Spring事务的隔离级别？ 默认值？
TransactionDefinition :         
定义了与java.lang.sql同名的四个隔离级别，     
还有一个 默认的隔离级别表示使用底层数据库的默认隔离级别

##### Spring事务的传播属性？ 默认值？
默认值
```text
Propagation propagation() default Propagation.REQUIRED;
如果当前没有事务，新建一个事务，如果已经存在一个事务，加入到这个事务
```
7种类型的事务传播行为
```text
PROPAGATION_REQUIRED ：如果当前没有事务，新建一个事务，如果已经存在一个事务，加入到这个事务

PROPAGATION_SUPPORTS ：如果当前有事务，加入这个事务，否则以非事务方式运行

PROPAGATION_MANDATORY : 如果当前有事务，加入这个事务，否则抛出异常

PROPAGATION_REQUIRES_NEW ： 新建事务，挂起当前事务

PROPAGATION_NOT_SUPPORTED ：不允许事务，如果当前有事务，抛出异常

PROPAGATION_NEVER ：如果当前没有事务，新建一个事务，如果已经存在一个事务，新建一个事务保存点

PROPAGATION_NESTED： 使用嵌套事务时，底层数据源需要基于JDBC3.0，支持保存点
```


##### spring 事务不生效(@Transactional注解无效)的场景
```text
1. 如果不是Innodb存储引擎，MyISAM不支持事务。

2. 没有指定rollbackFor参数默认只会捕获RuntimeException 和 Error 来进行回滚。

3. 没有指定transactionManager参数，默认的transactionManager并不是我期望的，以及一个事务中涉及到了多个数据库。

4. 如果AOP使用了JDK动态代理，对象内部方法互相调用不会被Spring的AOP拦截，       
另外只能代理public方法或者 public final 方法  ，         
代理 protected、 static 方法无效（接口的方法必须是public，而JDK动态代理是生成接口的子类）

5. 如果AOP使用了CGLIB代理，需要动态创建子类 复写方法，所以不能使用 private、static、final   
（private ：子类无法访问到 、static ：类级别的方法，无法被子类覆盖， final：子类无法覆盖）

如果调用者没有事务上下文，4、5这两种情况的 @Transactional注解就是无效的，       
如果调用者有事务上下文，4、5是可以加入到外部调用方法的事务上下文
```

### SpringBoot 自动装配的原理
Spring Boot在启动的时候
 1. 会将主配置类（即@SpringBootApplication标注的类）的所在包及子包里面所有组件扫描加载到Spring容器
 2. 会从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，     
将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作。     
以前我们需要自己配置的东西，自动配置类都帮我们完成了


### springboot的启动流程
构造SpringApplication的时候会进行初始化的工作，初始化的时候会做以下几件事：

1.把参数sources设置到SpringApplication属性中，这个sources可以是任何类型的参数。

2.判断是否是web程序，并设置到webEnvironment这个boolean属性中。 

3.找出所有的初始化器，默认有5个，设置到initializers属性中 。

4.找出所有的应用程序监听器，默认有9个，设置到listeners属性中 。

5.找出运行的主类(main class) 。

SpringApplication构造完成之后调用run方法，启动SpringApplication，run方法执行的时候会做以下几件事：

1.构造一个StopWatch，观察SpringApplication的执行 。

2.找出所有的SpringApplicationRunListener并封装到SpringApplicationRunListeners中，用于监听run方法的执行。监听的过程中会封装成事件并广播出去让初始化过程中产生的应用程序监听器进行监听 。

3.构造Spring容器(ApplicationContext)，并返回 。

    3.1 创建Spring容器的判断是否是web环境，是的话构造AnnotationConfigEmbeddedWebApplicationContext，否则构造 AnnotationConfigApplicationContext 。

    3.2 初始化过程中产生的初始化器在这个时候开始工作 。

    3.3 Spring容器的刷新(完成bean的解析、各种processor接口的执行、条件注解的解析，aware接口的回调 等等) 。

4.从Spring容器中找出ApplicationRunner和CommandLineRunner接口的实现类并排序后依次执行。



---

## 5 Mybatis
### 1. 为什么要用 mybatis 这种持久层框架？
1. 原始的JDBC 访问数据库，没有用到数据库连接池，频繁创建销毁连接影响效率        
```
mybatis 内部实现了 数据库连接池
```

2. sql、配置文件耦合在代码里，不方便全局修改
```text
mybatis 通过读取配置信息，赋值给 Configuration， 

全局单例配置对象 SqlSessionFactory 持有 Configuration
```

3. 消除了重复的模板代码
```text
1. 获取连接，参数替换
2. 释放连接
3. 处理异常 
```

### 2. 自己怎么实现mybatis，实现原理
1. 获取数据库连接

2. 获取sql，参数替换

3. 执行sql，处理返回值

### 3. mybatis 一二级缓存配置
1. 默认开启，一级缓存是Session会话级别的缓存，位于表示一次数据库会话的SqlSession对象之中，又被称之为本地缓存。一级缓存是MyBatis内部实现的一个特性，用户不能配置，默认情况下自动支持的缓存，用户没有定制它的权利（不过这也不是绝对的，可以通过开发插件对它进行修改）；

2. 二级缓存是 每一个Mapper都可以拥有一个Cache对象
```java
1.  MyBatis支持二级缓存的总开关：全局配置变量参数   cacheEnabled=true

   2. 该select语句所在的Mapper，配置了<cache> 或<cached-ref>节点，并且有效

   3. 该select语句的参数 useCache=true
```
---

## 6 Rabbit MQ

### Rabbit MQ 架构设计 
生产者、信道（交换器、绑定、队列）、消费者

集群模式，至少一个磁盘节点

### 如果 Rabbit MQ 挂掉了，后续流程怎么处理
搭建 Rabbit集群， Rabbit集群允许消费者和生产者在单个Rabbit MQ节点崩溃时 继续运行， 

如果集群中唯一的磁盘节点崩溃的话，集群仍然可以保持运行，但是无法更改任何东西      
可以在集群中设置多个磁盘节点

### 消息持久化
如果消息要从 MQ重启后恢复，消息必须
1. 投递模式选项设置为2 （持久）
2. 发送到持久化的交换器（durable 为 true）
3. 达到持久化的队列（durable 为 true）

MQ确保消息能从服务器重启中恢复的方式是 把消息写入磁盘上的一个持久化日志文件，        
当发送一条持久化消息到交换器，Rabbit MQ 会在消息保存到日志文件后发送响应

Rabbit MQ 会在消费者消费后把持久化消息标记为等待垃圾回收

在消费之前，如果 Rabbit MQ重启，Rabbit MQ会重播日志文件中的消息到对应的队列 或者交换器

持久化消息到磁盘会影响吞吐效率

### Rabbit MQ 如何保证消息正确投递
##### 1、生产者丢数据
RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。

transaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。

然而缺点就是吞吐量下降了，生产上用confirm模式的居多。
```text
一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)

一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)

这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。

相关接口 ：
org.springframework.amqp.core.AmqpTemplate#convertSendAndReceive(java.lang.String, java.lang.String, java.lang.Object, org.springframework.amqp.core.MessagePostProcessor)
```

##### 2、消息队列丢数据
开启持久化磁盘的配置，在消息持久化磁盘后，再给生产者发送一个Ack信号。
           
这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。
      
如何持久化呢，下面两步

1、将queue的持久化标识durable设置为true,则代表是一个持久的队列

2、发送消息的时候将deliveryMode=2

##### 3、消费者丢数据
消费者丢数据一般是因为采用了自动确认消息模式。

这种模式下，消费者会自动确认收到信息。这时rahbitMQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息。

至于解决方案，==采用手动确认消息即可==  



### 如何保证消息不被重复消费？
这个问题其实换一种问法就是，如何保证消息队列的幂等性?

**正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除**

RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念

#### 造成重复消费的原因?
 就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者
 
#### 针对业务场景来答分以下几点

1、比如，你拿到这个消息做数据库的insert操作。

那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。

2、再比如，你拿到这个消息做redis的set的操作

那就容易了，不用解决。因为你无论set几次结果都是一样的，set操作本来就算幂等操作。

3、如果上面两种情况还不行，上大招。

准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录 

### 如何保证消息的顺序性？
通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(rabbitMq中就是queue)。        
然后只用一个消费者去消费该队列。

---


## 7 Redis

### 为什么单线程更加快
- 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU
    - 不用去考虑各种锁的问题，不存在加锁释放锁操作
- 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速
- 数据结构简单，对数据操作也简单
- 使用多路I/O复用模型，非阻塞IO
    - 多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，
    
#### 
但是，我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！

Redis进行持久化的时候会以子进程或者子线程的方式执行        

### 持久化方案

#### 快照模式（RDB）
在写操作不是特别频繁，允许丢失部分数据的场景下，    
设置 每隔一段时间，达到一定写操作数量 ，进行自动保存，生成快照文件，或者进行手动保存
- save
- bgsave ： fork子进程保存快照

#### AOF（Append Only File） 模式
同步写选项、同步频率
- always        
    每个写命令都同步写入硬盘，会严重降低Redis 速度
- everysec      
    每秒执行一次同步，将多个写命令同步到硬盘
- no        
    让操作系统决定何时同步，不推荐

### 主从配置、哨兵模式，集群模式
==只有主服务器接受写命令==

#### 更换故障主服务器
##### 方法一：升级当前从服务器为主服务器

##### 方法二
1. 复制从服务器数据到新的机器，
2. 在新的机器上启动redis
3. 为从服务器指定新的主服务器

#### redis集群是如何同步数据的？

#### Redis复制过程  
SLAVEOF host port 设置当前服务器为 某台服务器的从服务器

1. 从服务器连接主服务器，发送SYNC命令
2. 主服务器执行 BGSAVE,在缓存区记录BGSAVE之后写入的命令，       
从服务器会根据配置选择清空自身数据，或向客户端返回错误

可以为从服务器指定新的从服务器，构成从服务器树

#### 哨兵模式 Redis Sentinel
目的是为了提供自动故障转移服务

配合Redis复制功能，Redis Sentinel是运行在特殊模式下的服务器     
它会监视一系列主服务器和对应的从服务器，        
==当主服务器失效时==，监视这个主服务器的所有Sentinel会基于彼此共有的信息选出一个新的主服务器，       
其他的从服务器会去复制这个新的主服务器

### 缓存雪崩和失效的场景
热点缓存key失效，大量请求直接访问数据库，导致数据库连接耗尽；
    
解决方案：
- 查询前参数合理性校验
- 设置不同的过期时间
- 在查询数据库数据之前再查一遍redis（双重检查），查询数据库之后，新建redis缓存，设置过期时间 
- 应对大规模查询（应对秒杀活动），将查询放入消息队列

---

## 8 SpringCloud 中间件

### 服务注册、服务发现 Eureka
拉去Eureka服务端配置，并且不注册自身
```java
eureka:
  client:
    registerWithEureka: false
    serviceUrl:
      #      指定服务注册中心的地址
      defaultZone: http://localhost:8061/eureka/
```

### Http客户端 Feign

#### Feign设置超时时间
使用Feign调用接口分两层，ribbon的调用和hystrix的调用，所以ribbon的超时时间和Hystrix的超时时间的结合就是Feign的超时时间
```java
#hystrix的超时时间
hystrix:
    command:
        default:
            execution:
              timeout:
                enabled: true
              isolation:
                    thread:
                        timeoutInMilliseconds: 9000
#ribbon的超时时间
ribbon:
  ReadTimeout: 3000
  ConnectTimeout: 3000
  MaxAutoRetries: 1 #同一台实例最大重试次数,不包括首次调用
  MaxAutoRetriesNextServer: 1 #重试负载均衡其他的实例最大重试次数,不包括首次调用
  OkToRetryOnAllOperations: false  #是否所有操作都重试 

一般情况下 都是 ribbon 的超时时间（<）hystrix的超时时间（因为涉及到ribbon的重试机制）
因为ribbon的重试机制和Feign的重试机制有冲突，所以源码中默认关闭Feign的重试机制

hystrix超时时间的计算： (1 + MaxAutoRetries + MaxAutoRetriesNextServer) * ReadTimeout 

当ribbon超时后且hystrix没有超时，便会采取重试机制。当OkToRetryOnAllOperations设置为false时，只会对get请求进行重试。如果设置为true，便会对所有的请求进行重试，如果是put或post等写操作，如果服务器接口没做幂等性，会产生不好的结果，所以OkToRetryOnAllOperations慎用。

如果不配置ribbon的重试次数，默认会重试一次        
注意：     
默认情况下,GET方式请求无论是连接异常还是读取异常,都会进行重试
非GET方式请求,只有连接异常时,才会进行重试

```


### 负载均衡 ribbon、


### 服务降级 Hystrix

---

## 9 Zookeeper

主节点失效，备份主节点需要通过选举，成为新的主节点，      
如果旧的主节点恢复，==如何避免存在两个主节点（脑裂）==

从节点如果失效，主节点应该能够检测到，不在继续派发任务给失效节点，       
重新派发未完成任务给其他节点，==如何避免重复消费==

主从节点 保持通信

#### 几个重要的 父znode
/workers  /assign     /tasks

### zookeeper 实现分布式锁
一个线程尝试创建 临时节点 /lock, (临时节点会在会话过期 或关闭时 自动被删除) 
```text
create -e /lock ""
```
其他线程因为节点存在，无法创建/lock   
监听到 /lock 删除时，再次尝试创建 /lock，如果其他线程创建 /lock 成功，继续监听 /lock

#### 在主节点上增加监视点
```text
stat /master true
```

#### 设置 子节点的监视点
```text
ls /workers true
```

#### Zookeeper一致性协议原理Zab ，ZAB（ZooKeeper Atomic Broadcast ） 全称为：原子消息广播协议
ZAB可以说是在Paxos算法基础上进行了扩展改造而来的，ZAB协议设计了支持崩溃恢复

ZooKeeper使用单一主进程Leader用于处理客户端所有事务请求，采用ZAB协议将服务器数状态 以事务形式 广播到所有Follower上；

##### ZAB协议的两个基本模式：恢复模式和广播模式

恢复模式:（选举）
当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数server完成了和leader的状态同步以后，恢复模式就结束了


广播模式：（数据同步）     
ZooKeeper服务一直维持在广播状态，直到Leader崩溃了或者Leader失去了大部分的Followers支持。

广播模式极其类似于分布式事务中的2pc（two-phrase commit 两阶段提交）：       
即Leader提起一个决议，由Followers进行投票，Leader对投票结果进行计算决定是否通过该决议，如果通过执行该决议（事务），否则什么也不做

---

## 设计模式

### 用过的设计模式有哪些

## 10 性能优化

### 线上oom怎么排查
查看日志、分析dump文件，查看占用内存较多的对象

1. ps -aux|grep java 当服务重新部署后，可以找出当前Java进程的PID

2. jstat -gcutil pid interval 用于查看当前GC的状态,它对Java应用程序的资源和性能进行实时的命令行的监控，包括了对Heap size和垃圾回收状况的监控

3. jmap -histo:live pid 可用统计存活对象的分布情况，从高到低查看占据内存最多的对象。上图

4. 分析dump文件

#### 如果一个 前端请求查询耗时很长，怎么优化
- 查看nginx日志，是否是网络问题
- top命令查看 服务器内存 、IO情况，
- 查看服务日志，是否代码逻辑不合理，是否有多线程锁竞争
- 开启慢查询，是否有较慢的sql，能否优化查询，优化索引
- 热点数据是够可以缓存
![image](https://img-blog.csdnimg.cn/20190111141308700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdhZGFt,size_16,color_FFFFFF,t_70)
- 第三方接口调用超时


- 线上内存溢出的场景和处理方法
    - top定位查看服务器状态，获取占用内存多的进程ID，保存线程栈信息，
    - 下载dump文件，分析 dump文件

- zookeeper / eureka 配置本地调用公共服务

#### [nginx中的超时设置，请求超时、响应等待超时等](https://blog.csdn.net/qq_29663071/article/details/81061420)


## 其他

#### 从1000w个数字中找出最小的10个并打印
advance.sort.HeapSort.findMinTopK

---

- [记一次蚂蚁金服的面试经历](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485070&idx=1&sn=31894a1bdda357d897962a9fc3a994b7&chksm=cea24945f9d5c0531db568321f1d8d7a4e848e04aa2df18e589db9ba4aafee0fb0cebb965252&token=463285003&lang=zh_CN&scene=21#wechat_redirect)

https://www.bilibili.com/read/cv5554230?share_medium=android&share_source=weixin&bbid=87E1A2EB-DC6F-4726-A9A5-51D5A927762310277infoc&ts=1586753871769