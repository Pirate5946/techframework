- [并发知识点 - 在线整理](http://concurrent.redspider.group/article/01/2.html)
- [参考博客 - 0](https://blog.csdn.net/cai13070139328/article/details/98874110)
- [参考博客 - 并发编程知识点](http://concurrent.redspider.group/article/01/1.html)
- [Synchronized关键字深析（小白慎入，深入jvm源码，两万字长文）
](https://blog.csdn.net/weixin_42762133/article/details/103241439?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendHotData-14&utm_source=distribute.pc_relevant.none-task-blog-BlogCommendHotData-14)
---

### 可见性

### 有序性 ：   
线程的启动先后顺序 与执行先后顺序无关，Jvm和操作系统一起决定了线程的执行顺序

如何控制线程的执行顺序？

### 原子性

---

### 1.0 Java并发编程基本知识介绍
http://www.tianshouzhi.com/api/tutorials/mutithread


http://www.tianshouzhi.com/api/tutorials/mutithread/67

竞态条件：当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件

对象锁：同步在一个对象上的同步块，在同一时刻只能被一个线程进入 并执行操作,    其他等待进入该同步块的线程将被阻塞，直到执行该同步块中的线程退出。

#### [四种不同的同步块](https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&mid=2247487657&idx=2&sn=92bf444364a56eda2b64fc3bb3e2a4a7&chksm=ec6e69f1db19e0e7f33c912ac1173769a228a9efec276f772f4fa85e59bbe9421f27e854954b&mpshare=1&scene=1&srcid=&sharer_sharetime=1575244298056&sharer_shareid=40ab0d7d5cfdb4218441d9441c4831a6#rd) 
1. 实例方法     
对于普通同步方法（实例方法），锁是当前实例对象
  
    synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法
    同步在拥有该方法的对象上，   
    注意：多个线程要运行的是同一个对象实例的同步方法，   
    如果一个每个线程运行的是不同的对象实例的同步方法，是没有同步效果的，  
    因为每个对象实例是把自身当成锁，就导致没有公用一个锁。
    
2. 实例方法中的同步块    
对于同步方法块，锁是synchronized 括号里的配置的对象
      
    synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令
    在同步构造器中用括号括起来的对象叫做监视器对象,监视器对象可以是任意一个对象的class实例      
    如果两个同步块不是同步在同一个class对象上。那么这两个同步块可以同时被线程访问
    
3. 静态方法         
对于静态同步方法，锁是当前类的Class对象

    使用的是类锁，同一个类的不同对象 用的也是同一个锁    
    
注意：当一个线程正在访问一个对象的 synchronized 实例方法，那么其他线程不能访问该对象的其他 synchronized 方法，   毕竟一个对象只有一把锁，    
当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized实例方法，     
但是其他线程还是可以访问该实例对象的其他非synchronized方法。
   
==总之，Java的每一个对象都可以作为锁，只要访问的是同一个对象，那就受限于此对象的锁，不同的对象则不会相互干扰==

#### synchronized底层实现原理
Java 虚拟机中的同步(Synchronization)基于进入和退出 Monitor对象 来实现方法同步和代码块同步,Monitor对象存放在Java对象头中

Java对象在HotSpot虚拟机中的内存布局可分为3块区域：对象头(Header)、实例数据(Instance Data)和对齐填充(Padding)。

synchronized用的锁是存储在Java对象头里的，JVM采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，    
其主要结构是由Mark Word 和 Class Metadata Address 两个部分组成

在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的

注意： 
1. synchronized同步块对于同一线程来说是可重入的，即不会自己锁死自己
2. 同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入

效率问题：       
因为Java的线程是映射在操作系统原生线程之上的，阻塞或唤醒一个线程，都需要操作系统帮忙完成，     
这就需要从用户态转换到核心态中，而这个状态之间的转换需要相对比较长的处理器时间，        
对此HotSpot虚拟机开发团队对synchronized锁进行了大量的优化措施。


#### CAS
在使用synchronized时，线程获取锁是一种悲观锁策略，即假设每一次执行临界区代码都会产生冲突，所以当前线程获取到锁的时候同时也会阻塞其他线程获取该锁。

而CAS（compare and swap）又叫做比较交换操作是一种乐观锁策略         
先进行比较操作，如果没有其他线程竞争共享数据就操作成功了；如果共享数据有争用，出现冲突了就重试当前操作直到没有冲突为止
##### CAS带来的ABA问题
atomic包中提供了AtomicStampedReference来解决ABA问题相当于添加了版本号

#### 锁的优化
锁的状态从低到高一共有四种：无锁状态、偏向锁、轻量级锁和重量级锁。这几个状态会随着竞争情况逐渐升级，但锁不可降级，意味着锁从偏向锁升级到轻量级锁后不能再回到偏向锁级，这是为了提高获得和释放锁的效率。

##### 1.偏向锁
偏向锁在JVM是默认启动的,竞争激烈的情况下应该通过JVM参数关闭：UserBiasedLocking = false,那么程序默认进入轻量级锁状态。

#### 线程状态 、主要方法
http://concurrent.redspider.group/article/01/4.html

![image](http://concurrent.redspider.group/article/01/imgs/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E5%9B%BE.png)

### Java线程间的通信
http://concurrent.redspider.group/article/01/5.html

#### 5.1 锁与同步

#### 5.2 等待/通知机制

#### 5.3 信号量

多个线程（超过2个）需要相互合作，我们用简单的“锁”和“等待通知机制”就不那么方便了。这个时候就可以用到信号量

#### 5.4 管道

#### 5.5 其它通信相关
以上介绍了一些线程间通信的基本原理和方法。除此以外，还有一些与线程通信相关的知识点，这里一并介绍。

##### 5.5.1 join方法
join()方法是Thread类的一个实例方法。它的作用是让当前线程陷入“等待”状态，等join的这个线程执行完成后，再继续执行当前线程

##### 5.5.2 sleep方法
sleep方法是不会释放当前的锁的，而wait方法会。这也是最常见的一个多线程面试题。
- wait可以指定时间，也可以不指定；而sleep必须指定时间。
- wait释放cpu资源，同时释放锁；sleep释放cpu资源，但是不释放锁，所以易死锁。
- wait必须放在同步块或同步方法中，而sleep可以再任意位置

##### 5.5.3 ThreadLocal类
ThreadLocal是一个本地线程副本变量工具类。内部是一个弱引用的Map来维护

ThreadLocal类并不属于多线程间的通信，而是让每个线程有自己”独立“的变量，线程之间互不影响。它为每个线程都创建一个副本，每个线程可以访问自己内部的副本变量。

最常见的ThreadLocal使用场景为用来解决数据库连接、Session管理等。数据库连接和Session管理涉及多个复杂对象的初始化和关闭

##### 5.5.4 InheritableThreadLocal
  InheritableThreadLocal类与ThreadLocal类稍有不同，Inheritable是继承的意思。它不仅仅是当前线程可以存取副本值，而且它的子线程也可以存取这个副本值 
  
## Java内存模型基础知识  
### 既然堆是共享的，为什么在堆中会有内存不可见问题？   
根据JMM的规定，线程对共享变量的所有操作都必须在自己的本地内存中进行，不能直接从主内存中读取。  

JMM通过控制主内存与每个线程的本地内存之间的交互，来提供内存可见性保证

    Java中的volatile关键字可以保证多线程操作共享变量的可见性以及禁止指令重排序，synchronized关键字不仅保证可见性，同时也保证了原子性（互斥性）
    
    在更底层，JMM通过内存屏障来实现内存的可见性以及禁止重排序

### 7.1 什么是重排序？
计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排。

    
指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。所以在多线程下，指令重排序可能会导致一些问题。

### 7.2 顺序一致性模型与JMM的保证
使用volatile、final、synchronized等关键字来实现多线程下的同步    

JMM的具体实现方针是：在不改变（正确同步的）程序执行结果的前提下，尽量为编译期和处理器的优化打开方便之门。

### 7.3 happens-before
happens-before关系的定义如下：

1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。

2. 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM也允许这样的重排序。

在Java中，有以下天然的happens-before关系：

- 程序顺序规则：一个线程中的每一个操作，happens-before于该线程中的任意后续操作。
- 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
- volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
- 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
- start规则：如果线程A执行操作ThreadB.start()启动线程B，那么A线程的ThreadB.start（）操作happens-before于线程B中的任意操作、
- join规则：如果线程A执行操作ThreadB.join（）并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回


重排序有两类，JMM对这两类重排序有不同的策略：

1. 会改变程序执行结果的重排序，比如 A -> C，JMM要求编译器和处理器都禁止这种重排序。
2. 不会改变程序执行结果的重排序，比如 A -> B，JMM对编译器和处理器不做要求，允许这种重排序

## 8. volatile
从volatile的内存语义上来看，volatile可以保证内存可见性且禁止重排序。

volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁可以保证整个临界区代码的执行具有原子性。所以在功能上，锁比volatile更强大；在性能上，volatile更有优势

### 8.2.1 禁止重排序
JVM是怎么还能限制处理器的重排序的呢？它是通过内存屏障来实现的。

什么是内存屏障？硬件层面，内存屏障分两种：读屏障（Load Barrier）和写屏障（Store Barrier）。内存屏障有两个作用：

阻止屏障两侧的指令重排序；
强制把写缓冲区/高速缓存中的脏数据等写回主内存，或者让缓存中相应的数据失效。

## 9 [synchronized与锁](http://concurrent.redspider.group/article/02/9.html)
Java多线程的锁都是基于对象的，Java中的每一个对象都可以作为一个锁。

还有一点需要注意的是，我们常听到的类锁其实也是对象锁。

Java类只有一个Class对象（可以有多个实例对象，多个实例共享这个Class对象），而Class对象也是特殊的Java对象。        
所以我们常说的类锁，其实就是Class对象的锁。

### 9.1 Synchronized关键字
所谓“临界区”，指的是某一块代码区域，它同一时刻只能由一个线程执行

### 9.2 几种锁
Java 6 为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁“。在Java 6 以前，所有的锁都是”重量级“锁。所以在Java 6 及其以后，一个对象其实有四种锁状态，它们级别由低到高依次是：

- 无锁状态
- 偏向锁状态
- 轻量级锁状态
- 重量级锁状态


#### 9.2.2 偏向锁
偏向锁在资源无竞争情况下消除了同步语句，连CAS操作都不做了，提高了程序的运行性能。

所以，如果应用程序里所有的锁通常出于竞争状态，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭：
    
    -XX:UseBiasedLocking=false。

#### 9.2.3 轻量级锁
JVM会为每个线程在当前线程的栈帧中创建用于存储锁记录的空间，我们称为Displaced Mark Word。如果一个线程获得锁的时候发现是轻量级锁，会把锁的Mark Word复制到自己的Displaced Mark Word里面。

#### 9.2.4 重量级锁

#### 9.2.5 总结锁的升级流程

### [第十章 乐观锁和悲观锁](http://concurrent.redspider.group/article/02/10.html)

#### 悲观锁
悲观锁就是我们常说的锁。对于悲观锁来说，它总是认为每次访问共享资源时会发生冲突，所以必须对每次数据操作加上锁，以保证临界区的程序同一时间只能有一个线程在执行。

#### 乐观锁：
     
     乐观锁又称为“无锁”，顾名思义，它是乐观派。乐观锁总是假设对共享资源的访问没有冲突，线程可以不停地执行，无需加锁也无需等待。而一旦多个线程发生冲突，乐观锁通常是使用一种称为CAS的技术来保证线程执行的安全性。
     
     由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说乐观锁天生免疫死锁。
     
     乐观锁多用于“读多写少“的环境，避免频繁加锁影响性能；而悲观锁多用于”写多读少“的环境，避免频繁失败和重试影响性能。
     
#### CAS
当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。
     
#### 10.3 Java实现CAS的原理 - Unsafe类
```text
Unsafe中对CAS的实现是C++写的，它的具体实现和操作系统、CPU都有关系。

Linux的X86下主要是通过cmpxchgl这个指令在CPU级完成CAS操作的，但在多处理器情况下必须使用lock指令加锁来完成。当然不同的操作系统和处理器的实现会有所不同，大家可以自行了解。

当然，Unsafe类里面还有其它方法用于不同的用途。比如支持线程挂起和恢复的park和unpark， LockSupport类底层就是调用了这两个方法。还有支持反射操作的allocateInstance()方法。

```
#### 10.4 原子操作-AtomicInteger类源码简析
weakCompareAndSet操作仅保留了volatile自身变量的特性，而出去了happens-before规则带来的内存语义。     

#### 10.5 CAS实现原子操作的三大问题

##### 10.5.1 ABA问题
      所谓ABA问题，就是一个值原来是A，变成了B，又变回了A。这个时候使用CAS是检查不出变化的，但实际上却被更新了两次。
      
      ABA问题的解决思路是在变量前面追加上版本号或者时间戳。从JDK 1.5开始，JDK的atomic包里提供了一个类AtomicStampedReference类来解决ABA问题。     
      
##### 10.5.2 循环时间长开销大
      CAS多与自旋结合。如果自旋CAS长时间不成功，会占用大量的CPU资源。
      
      解决思路是让JVM支持处理器提供的pause指令。
      
      pause指令能让自旋失败时cpu睡眠一小段时间再继续自旋，从而使得读操作的频率低很多,为解决内存顺序冲突而导致的CPU流水线重排的代价也会小很多。      
      
##### 10.5.3 只能保证一个共享变量的原子操作
      这个问题你可能已经知道怎么解决了。有两种解决方案：
      
      使用JDK 1.5开始就提供的AtomicReference类保证对象之间的原子性，把多个变量放到一个对象里面进行CAS操作；
      使用锁。锁内的临界区代码可以保证只有当前线程能操作      

### [第十一章 AQS](http://concurrent.redspider.group/article/02/11.html)
AQS是AbstractQueuedSynchronizer的简称，即抽象队列同步器
  
AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的同步器，比如我们提到的ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。 
  
  
#### 11.2 AQS的数据结构
AQS内部使用了一个volatile的变量state来作为资源的标识。同时定义了几个获取和改版state的protected方法，子类可以覆盖这些方法来实现自己的逻辑：

AQS类本身实现的是一些排队和阻塞的机制,内部使用了一个先进先出（FIFO）的双端队列，并使用了两个指针head和tail用于标识队列的头部和尾部

但它并不是直接储存线程，而是储存拥有线程的Node节点。

![image](http://concurrent.redspider.group/article/02/imgs/AQS%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png)
  
#### 11.3 资源共享模式
资源有两种共享模式，或者说两种同步方式：
```text
独占模式（Exclusive）：资源是独占的，一次只能一个线程获取。如ReentrantLock。
共享模式（Share）：同时可以被多个线程获取，具体的资源个数可以通过参数指定。如Semaphore/CountDownLatch。
一般情况下，子类只需要根据需求实现其中一种模式，当然也有同时实现两种模式的同步类，如ReadWriteLock。
```

#### 11.4 AQS的主要方法源码解析
AQS的设计是基于模板方法模式的，它有一些方法必须要子类去实现的

```text
isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。

tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。

tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。

tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。

tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。
```
结点进入等待队列后，是调用park使它进入阻塞状态的。只有头结点的线程是处于活跃状态的

获取资源的方法除了acquire外，还有以下三个：
```text
acquireInterruptibly：申请可中断的资源（独占模式）
acquireShared：申请共享模式的资源
acquireSharedInterruptibly：申请可中断的资源（共享模式）
```

#### 11.4.2 释放资源


## [第十二章 线程池原理](http://concurrent.redspider.group/article/03/12.html)

### 12.1 为什么要使用线程池
使用线程池主要有以下三个原因：
```text
创建/销毁线程需要消耗系统资源，线程池可以复用已创建的线程。
控制并发的数量。并发数量过多，可能会导致资源消耗过多，从而造成服务器崩溃。（主要原因）
可以对线程做统一管理。
```

### 12.2 线程池的原理
    Java中的线程池顶层接口是Executor接口，ThreadPoolExecutor 是这个接口的实现类。

#### 12.2.1 ThreadPoolExecutor提供的构造方法
涉及到5~7个参数，我们先看看必须的5个参数是什么意思：

```text
int corePoolSize：该线程池中核心线程数最大值

int maximumPoolSize：该线程池中线程总数最大值 。

long keepAliveTime：非核心线程闲置超时时长。

TimeUnit unit：keepAliveTime的单位。

BlockingQueue workQueue：阻塞队列，维护着等待执行的Runnable任务对象。

```

两个非必须的参数。
```text
ThreadFactory threadFactory : 创建线程的工厂 ，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂。

RejectedExecutionHandler handler:拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为 ：
                                 
四种拒绝处理的策略为 ：

ThreadPoolExecutor.AbortPolicy：默认拒绝处理策略，丢弃任务并抛出RejectedExecutionException异常。

ThreadPoolExecutor.DiscardPolicy：丢弃新来的任务，但是不抛出异常。

ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列头部（最旧的）的任务，然后重新尝试执行程序（如果再次失败，重复此过程）。

ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务。
```

#### 12.2.2 ThreadPoolExecutor的策略
线程池也有自己的状态。ThreadPoolExecutor类中定义了一个volatile int变量runState来表示线程池的状态 ，分别为RUNNING、SHURDOWN、STOP、TIDYING 、TERMINATED。

#### 12.2.3 线程池主要的任务处理流程
处理任务的核心方法是execute
```
1. 线程总数量 < corePoolSize，无论线程是否空闲，都会新建一个核心线程执行任务（让核心线程数量快速达到corePoolSize，在核心线程数量 < corePoolSize时）。注意，这一步需要获得全局锁。
2. 线程总数量 >= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了线程复用）。
3. 当缓存队列满了，说明这个时候任务已经多到爆棚，需要一些“临时工”来执行这些任务了。于是会创建非核心线程去执行这个任务。注意，这一步需要获得全局锁。
4. 缓存队列满了， 且总线程数达到了maximumPoolSize，则会采取上面提到的拒绝策略进行处理。


ctl.get()是获取线程池状态，用int类型表示。第二步中，入队前进行了一次isRunning判断，入队之后，又进行了一次isRunning判断。

线程池的状态是时刻发生变化的。很有可能刚获取线程池状态后线程池状态就改变了。判断是否将command加入workqueue是线程池之前的状态。倘若没有二次检查，万一线程池处于非RUNNING状态（在多线程环境下很有可能发生），那么command永远不会执行。
```

#### 12.2.4 ThreadPoolExecutor如何做到线程复用的？
ThreadPoolExecutor在创建线程时，会将线程封装成工作线程worker(继承AQS),并放入工作线程组中，然后这个worker反复从阻塞队列中拿任务去执行

创建worker对象，并初始化一个Thread对象，然后启动这个线程对象。

首先去执行创建这个worker时就有的任务，当执行完这个任务后，worker的生命周期并没有结束，       
在while循环中，worker会不断地调用getTask方法从阻塞队列中获取任务然后调用task.run()执行任务,从而达到复用线程的目的。        
只要getTask方法不返回null,此线程就不会退出

当然，核心线程池中创建的线程想要拿到阻塞队列中的任务，先要判断线程池的状态，如果STOP或者TERMINATED，返回null。

核心线程的会一直卡在workQueue.take方法，被阻塞并挂起，不会占用CPU资源，直到拿到Runnable 然后返回（当然如果allowCoreThreadTimeOut设置为true,那么核心线程就会去调用poll方法，因为poll可能会返回null,所以这时候核心线程满足超时条件也会被销毁）。

非核心线程会workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) ，如果超时还没有拿到，下一次循环判断compareAndDecrementWorkerCount就会返回null,Worker对象的run()方法循环体的判断为null,任务结束，然后线程被系统回收 。


### 12.3 四种常见的线程池

#### 12.3.1 newCachedThreadPool
CacheThreadPool的运行流程如下：
```text
提交任务进线程池。
因为corePoolSize为0的关系， 不创建核心线程， 线程池最大为Integer.MAX_VALUE。
尝试将任务添加到SynchronousQueue队列。
如果SynchronousQueue入列成功，等待被当前运行的线程空闲后拉取执行。如果当前没有空闲线程，那么就创建一个非核心线程，然后从SynchronousQueue拉取任务并在当前线程执行。
如果SynchronousQueue已有任务在等待，入列操作将会阻塞。
```
当需要执行很多 ==短时间的任务== 时，CacheThreadPool的线程复用率比较高， 会显著的提高性能。而且线程60s后会回收，意味着即使没有任务进来，CacheThreadPool并不会占用很多资源。

#### 12.3.2 newFixedThreadPool
核心线程数量和总线程数量相等，都是传入的参数nThreads，所以只能创建核心线程，不能创建非核心线程。因为LinkedBlockingQueue的默认大小是Integer.MAX_VALUE，故如果核心线程空闲，则交给核心线程处理；如果核心线程不空闲，则入列等待，直到核心线程空闲。

与CachedThreadPool的区别：
```text
FixedThreadPool只会创建核心线程。 而CachedThreadPool因为corePoolSize=0，所以只会创建非核心线程。

在 getTask() 方法，如果队列里没有任务可取，线程会一直阻塞在 LinkedBlockingQueue.take() ，线程不会被回收。 CachedThreadPool会在60s后收回。

由于线程不会被回收，会一直卡在阻塞，所以没有任务的情况下， FixedThreadPool占用资源更多。

```

#### 12.3.3 newSingleThreadExecutor
有且仅有一个核心线程（ corePoolSize == maximumPoolSize=1），使用了LinkedBlockingQueue（容量很大），所以，不会创建非核心线程。所有任务按照先来先执行的顺序执行。如果这个唯一的线程不空闲，那么新来的任务会存储在任务队列里等待执行。

#### 12.3.4 newScheduledThreadPool
创建一个定长线程池，支持定时及周期性任务执行。

## [第十三章 阻塞队列](http://concurrent.redspider.group/article/03/13.html)
BlockingQueue一般用于生产者-消费者模式，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。BlockingQueue就是存放元素的容器。

当缓冲池空了，我们需要阻塞消费者，唤醒生产者；当缓冲池满了，我们需要阻塞生产者，唤醒消费者

### 13.2 BlockingQueue的操作方法
阻塞队列提供了四组不同的方法用于插入、移除、检查元素：
```text
offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.

put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续

take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到Blocking有新的对象被加入为止 

poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null

```
不能往阻塞队列中插入null,会抛出空指针异常。

可以访问阻塞队列中的任意元素，调用remove(o)可以将队列之中的特定对象移除，但并不高效，尽量避免使用。

### 13.3 BlockingQueue的实现类

#### 13.3.1 ArrayBlockingQueue
由数组结构组成的有界阻塞队列。内部结构是数组，故具有数组的特性。

可以初始化队列大小， 且一旦初始化不能改变。构造方法中的fair表示控制对象的内部锁是否采用公平锁，默认是非公平锁。

#### 13.3.2 LinkedBlockingQueue
由链表结构组成的有界阻塞队列。内部结构是链表，具有链表的特性。默认队列的大小是Integer.MAX_VALUE，也可以指定大小。此队列按照先进先出的原则对元素进行排序。

#### 13.3.3 DelayQueue
该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 。注入其中的元素必须实现 java.util.concurrent.Delayed 接口。 

DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。 

#### 13.3.4 PriorityBlockingQueue
基于优先级的无界阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），内部控制线程同步的锁采用的是公平锁。

#### 13.3.5 SynchronousQueue
这个队列比较特殊，没有任何内部容量，甚至连一个队列的容量都没有。并且每个 put 必须等待一个 take，反之亦然。

##### 注意
PriorityBlockingQueue不会阻塞数据生产者（因为队列是无界的），而只会在没有可消费的数据时，阻塞数据的消费者。        
因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。     

对于使用默认大小的LinkedBlockingQueue也是一样的。

### 13.5 阻塞队列的原理
Lock锁的多条件（Condition）阻塞控制

#### 源码分析
构造器 ： 除了初始化队列的大小和是否是公平锁之外，还对同一个锁（lock）初始化了两个监视器，分别是notEmpty和notFull。这两个监视器的作用目前可以简单理解为标记分组，当该线程是put操作时，给他加上监视器notFull,标记这个线程是一个生产者；当线程是take操作时，给他加上监视器notEmpty，标记这个线程是消费者。

## [第十四章 锁接口和类](http://concurrent.redspider.group/article/03/14.html)
Java原生的锁——基于对象的锁，它一般是配合synchronized关键字来使用

### 14.1 synchronized的不足之处
- 如果临界区是只读操作，其实可以多线程一起执行，但使用synchronized的话，同一时间只能有一个线程执行。
- synchronized无法知道线程有没有成功获取到锁
- 使用synchronized，如果临界区因为IO或者sleep方法等原因阻塞了，而当前线程又没有释放锁，就会导致所有线程等待

### 14.2 锁的几种分类

#### 14.2.1 可重入锁和非可重入锁
重入锁 ： 这个锁支持一个线程对资源重复加锁

synchronized关键字就是使用的重入锁。比如说，你在一个synchronized实例方法里面调用另一个本实例的synchronized实例方法，它可以重新进入这个锁，不会出现任何异常。

如果我们自己在继承AQS实现同步器的时候，没有考虑到占有锁的线程再次获取锁的场景，可能就会导致线程阻塞，那这个就是一个“非可重入锁”。

ReentrantLock的中文意思就是可重入锁

#### 14.2.2 公平锁与非公平锁
这里的“公平”，其实通俗意义来说就是“先来后到”，也就是FIFO

如果对一个锁来说，先对锁获取请求的线程一定会先被满足，后对锁获取请求的线程后被满足，那这个锁就是公平的。反之，那就是不公平的

一般情况下，非公平锁能提升一定的效率。但是非公平锁可能会发生线程饥饿（有一些线程长时间得不到锁）的情况。所以要根据实际的需求来选择非公平锁和公平锁。

ReentrantLock支持非公平锁和公平锁两种。

#### 14.2.3 读写锁和排它锁
我们前面讲到的synchronized用的锁和ReentrantLock，其实都是“排它锁”。也就是说，这些锁在同一时刻只允许一个线程进行访问。

而读写锁可以再同一时刻允许多个读线程访问。Java提供了ReentrantReadWriteLock类作为读写锁的默认实现，内部维护了两个锁：一个读锁，一个写锁。通过分离读锁和写锁，使得在“读多写少”的环境下，大大地提高了性能。

注意，即使用读写锁，在写线程访问时，所有的读线程和其它写线程均被阻塞。

### 14.3 JDK中有关锁的一些接口和类

#### 14.3.1 抽象类AQS/AQLS/AOS
AQS里面的“资源”是用一个int类型的数据来表示

在JDK 1.6 中，多了一个AQLS（AbstractQueuedLongSynchronizer）。它的代码跟AQS几乎一样，只是把资源的类型变成了long类型。

AQS和AQLS都继承了一个类叫AOS（AbstractOwnableSynchronizer）。这个类也是在JDK 1.6 中出现的。这个类只有几行简单的代码。它是用于表示锁与持有者之间的关系（独占模式）。

#### 14.3.2 接口Condition/Lock/ReadWriteLock
每个对象都可以用继承自Object的wait/notify方法来实现等待/通知机制。而Condition接口也提供了类似Object监视器的方法，通过与Lock配合来实现等待/通知模式。

Condition和Object的wait/notify基本相似。其中，Condition的await方法对应的是Object的wait方法，而Condition的signal/signalAll方法则对应Object的notify/notifyAll()。但Condition类似于Object的等待/通知机制的加强版。

#### 14.3.3 ReentrantLock
内部有一个抽象类Sync，是继承了AQS，自己实现的一个同步器。        
同时，ReentrantLock内部有两个非抽象类NonfairSync和FairSync，它们都继承了Sync。从名字上看得出，分别是”非公平同步器“和”公平同步器“的意思。这意味着ReentrantLock可以支持”公平锁“和”非公平锁“。 

ReentrantLock的锁的”独占“的，也就是说，它的锁都是”排他锁“，不能共享。

在ReentrantLock的构造方法里，可以传入一个boolean类型的参数，来指定它是否是一个公平锁，默认情况下是非公平的。这个参数一旦实例化后就不能修改，只能通过isFair()方法来查看。

#### 14.3.4 ReentrantReadWriteLock
这个类也是一个非抽象类，它是ReadWriteLock接口的JDK默认实现。它与ReentrantLock的功能类似，同样是可重入的，支持非公平锁和公平锁。不同的是，它还支持”读写锁“。

ReentrantReadWriteLock实现了读写锁，但它有一个小弊端，就是在“写”操作的时候，其它线程不能写也不能读。我们称这种现象为“写饥饿”

#### 14.3.5 StampedLock
Java 8 才发布的，它没有实现Lock接口和ReadWriteLock接口，但它其实是实现了“读写锁”的功能，并且性能比ReentrantReadWriteLock更高。     
StampedLock还把读锁分为了“乐观读锁”和“悲观读锁”两种。

## [第十五章 并发容器集合](http://concurrent.redspider.group/article/03/15.html)

### 15.1 同步容器与并发容器
在java.util包下提供了一些容器类，而Vector和HashTable是线程安全的容器类，但是这些容器实现同步的方式是通过对方法加锁(sychronized)方式实现的，这样读写均需要锁操作，导致性能低下

即使是Vector这样线程安全的类，在面对多线程下的复合操作的时候也是需要通过客户端加锁的方式保证原子性。

并发容器是Java 5 提供的在多线程编程下用于代替同步容器，针对不同的应用场景进行设计，提高容器的并发访问性，同时定义了线程安全的复合操作。

### 15.2 并发容器类介绍

#### 15.2.1 并发Map

##### ConcurrentMap接口
ConcurrentMap接口继承了Map接口，在Map接口的基础上又定义了四个方法：
```text
putIfAbsent：与原有put方法不同的是，putIfAbsent方法中如果插入的key相同，则不替换原有的value值；

remove：与原有remove方法不同的是，新remove方法中增加了对value的判断，如果要删除的key-value不能与Map中原有的key-value对应上，则不会删除该元素;

replace(K,V,V)：增加了对value值的判断，如果key-oldValue能与Map中原有的key-value对应上，才进行替换操作；

replace(K,V)：与上面的replace不同的是，此replace不会对Map中原有的key-value进行比较，如果key存在则直接替换；
```

##### ConcurrentHashMap类
ConcurrentHashMap在JDK 1.7中，提供了一种粒度更细的加锁机制来实现在多线程下更高的性能，这种机制叫分段锁(Lock Striping)。

可以这样理解分段锁，就是将数据分段，对每一段数据分配一把锁。当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。

有些方法需要跨段，比如size()、isEmpty()、containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。

ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，HashEntry则用于存储键值对数据。

而在JDK 1.8中，ConcurrentHashMap主要做了两个优化：

- 同HashMap一样，链表也会在长度达到8的时候转化为红黑树，这样可以提升大量冲突时候的查询效率；
- 以某个位置的头结点（链表的头结点或红黑树的root结点）为锁，配合自旋+CAS避免不必要的锁开销，进一步提升并发性能。

##### ConcurrentNavigableMap接口与ConcurrentSkipListMap类


#### 15.2.2 并发Queue
JDK并没有提供线程安全的List类，因为对List来说，很难去开发一个通用并且没有并发瓶颈的线程安全的List。因为即使简单的读操作，拿contains() 这样一个操作来说，很难搜索的时候如何避免锁住整个list。

所以退一步，JDK提供了对队列和双端队列的线程安全的类：ConcurrentLinkedDeque和ConcurrentLinkedQueue。因为队列相对于List来说，有更多的限制。这两个类是使用CAS来实现线程安全的。

#### 15.2.3 并发Set
JDK提供了ConcurrentSkipListSet，是线程安全的有序的集合。底层是使用ConcurrentSkipListMap实现。

谷歌的guava框架实现了一个线程安全的ConcurrentHashSet：

## [第十六章 CopyOnWrite容器](http://concurrent.redspider.group/article/03/16.html)

### 16.1 什么是CopyOnWrite容器
CopyOnWrite容器即写时复制的容器,当我们往一个容器中添加元素的时候，不直接往容器中添加，而是将当前容器进行copy，复制出来一个新的容器，然后向新容器中添加我们需要的元素，最后将原容器的引用指向新容器。

这样做的好处在于，我们可以在并发的场景下对容器进行"读操作"而不需要"加锁"，从而达到读写分离的目的

### 16.2 CopyOnWriteArrayList
优点： CopyOnWriteArrayList由于其"读写分离"，遍历和修改操作分别作用在不同的List容器，所以在使用迭代器遍历的时候，则不会抛出异常

缺点： 
1. 数据量大的时候，内存会存在较大的压力，可能会引起频繁Full GC
2. 第二个缺点是CopyOnWriteArrayList由于实现的原因，写和读分别作用在不同新老容器上，在写操作执行过程中，读不会阻塞，但读取到的却是老容器的数据。
   
它只能保证最终数据一致性，所以如果我们希望写入的数据马上能准确地读取，请不要使用CopyOnWrite容器。

## [第十七章 通信工具类](http://concurrent.redspider.group/article/03/17.html)
```text
Semaphore	限制线程的数量
Exchanger	两个线程交换数据
CountDownLatch	线程等待直到计数器减为0时开始工作
CyclicBarrier	作用跟CountDownLatch类似，但是可以重复使用
Phaser	增强的CyclicBarrier
```

### 17.1 Semaphore
Semaphore翻译过来是信号的意思。顾名思义，这个工具类提供的功能就是多个线程彼此“打信号”。而这个“信号”是一个int类型的数据，也可以看成是一种“资源”。

可以在构造函数中传入初始资源总数，以及是否使用“公平”的同步器。默认情况下，是非公平的。

最主要的方法是acquire方法和release方法。acquire()方法会申请一个permit，而release方法会释放一个permit。当然，你也可以申请多个acquire(int permits)或者释放多个release(int permits)。

每次acquire，permits就会减少一个或者多个。如果减少到了0，再有其他线程来acquire，那就要阻塞这个线程直到有其它线程release permit为止。

Semaphore默认的acquire方法是会让线程进入等待队列，且会抛出中断异常。但它还有一些方法可以忽略中断或不进入阻塞队列：
```text
// 忽略中断
public void acquireUninterruptibly()
public void acquireUninterruptibly(int permits)

// 不进入等待队列，底层使用CAS
public boolean tryAcquire
public boolean tryAcquire(int permits)
public boolean tryAcquire(int permits, long timeout, TimeUnit unit)
        throws InterruptedException
public boolean tryAcquire(long timeout, TimeUnit unit)
```

#### 17.1.3 Semaphore原理
Semaphore内部有一个继承了AQS的同步器Sync，重写了tryAcquireShared方法。在这个方法里，会去尝试获取资源。

如果获取失败（想要的资源数量小于目前已有的资源数量），就会返回一个负数（代表尝试获取资源失败）。然后当前线程就会进入AQS的等待队列。
    
### 17.2 Exchanger
Exchanger类用于两个线程交换数据。它支持泛型，也就是说你可以在两个线程之间传送任何数据

当一个线程调用exchange方法后，它是处于阻塞状态的，只有当另一个线程也调用了exchange方法，它才会继续向下执行。看源码可以发现它是使用park/unpark来实现等待状态的切换的，但是在使用park/unpark方法之前，使用了CAS检查，估计是为了提高性能。

Exchanger一般用于两个线程之间更方便地在内存中交换数据，因为其支持泛型，所以我们可以传输任何的数据，比如IO流或者IO缓存。根据JDK里面的注释的说法，可以总结为一下特性：
```text
此类提供对外的操作是同步的；
用于成对出现的线程之间交换数据；
可以视作双向的同步队列；
可应用于基因算法、流水线设计等场景。
```
那么问题来了，Exchanger只能是两个线程交换数据吗？那三个调用同一个实例的exchange方法会发生什么呢？答案是只有前两个线程会交换数据，第三个线程会进入阻塞状态。

需要注意的是，exchange是可以重复使用的。也就是说。两个线程可以使用Exchanger在内存中不断地再交换数据。

### 17.3 CountDownLatch
假设某个线程在执行任务之前，需要等待其它线程完成一些前置任务，必须等所有的前置任务都完成，才能开始执行本线程的任务。

#### 17.3.3 CountDownLatch 原理
CountDownLatch类的原理挺简单的，内部同样是一个基层了AQS的实现类Sync，且实现起来还很简单，可能是JDK里面AQS的子类中最简单的实现了

#### 17.3.2 CountDownLatch案例
advance.thread.aqs.countdownlatchdemo.CountDownLatchDemo

需要注意的是构造器中的计数值（count）实际上就是闭锁需要等待的线程数量。这个值只能被设置一次，而且CountDownLatch没有提供任何机制去重新设置这个计数值。

### 17.4 CyclicBarrier
CyclicBarrier拥有CountDownLatch的所有功能，还可以使用reset()方法重置屏障。

#### 17.4.2 CyclicBarrier Barrier被破坏

#### 17.4.3 CyclicBarrier 案例
advance.thread.aqs.cyclicbarrierdemo.CyclicBarrierDemo

#### 17.4.4 CyclicBarrier原理
CyclicBarrier虽说功能与CountDownLatch类似，但是实现原理却完全不同，CyclicBarrier内部使用的是Lock + Condition实现的等待/通知模式。详情可以查看这个方法的源码：

### 17.5 Phaser
前面我们介绍了CyclicBarrier，可以发现它在构造方法里传入“任务总量”parties之后，就不能修改这个值了，并且每次调用await()方法也只能消耗一个parties计数。但Phaser可以动态地调整任务总量！

#### 17.5.2 Phaser案例
还是游戏的案例。假设我们游戏有三个关卡，但只有第一个关卡有新手教程，需要加载新手教程模块。但后面的第二个关卡和第三个关卡都不需要。我们可以用Phaser来做这个需求。

#### 17.5.3 Phaser原理
Phaser类的原理相比起来要复杂得多。它内部使用了两个基于Fork-Join框架的原子类辅助：
    

总的来说，CountDownLatch，CyclicBarrier，Phaser是一个比一个强大，但也一个比一个复杂。根据自己的业务需求合理选择即可。

## [第十八章 Fork/Join框架](http://concurrent.redspider.group/article/03/18.html)

### 18.1 什么是Fork/Join
Fork/Join框架是一个实现了ExecutorService接口的多线程处理器，它专为那些可以通过递归分解成更细小的任务而设计，最大化的利用多核处理器来提高应用程序的性能。

### 18.2 工作窃取算法
值得注意的是，当一个线程窃取另一个线程的时候，为了减少两个任务线程之间的竞争，我们通常使用双端队列来存储任务。被窃取的任务线程都从双端队列的头部拿任务执行，而窃取其他任务的线程从双端队列的尾部执行任务。

另外，当一个线程在窃取任务时要是没有其他可用的任务了，这个线程会进入阻塞状态以等待再次“工作”。

### 18.3 Fork/Join的具体实现
通常情况下，在创建任务的时候我们一般不直接继承ForkJoinTask，而是继承它的子类RecursiveAction和RecursiveTask。

#### 18.3.2 ForkJoinPool
ForkJoinPool是用于执行ForkJoinTask任务的执行（线程）池。

ForkJoinPool与传统线程池最显著的区别就是它维护了一个工作队列数组（volatile WorkQueue[] workQueues，ForkJoinPool中的每个工作线程都维护着一个工作队列）。

### 18.4 Fork/Join的使用
如果要计算的任务比较简单（比如我们案例中的斐波那契数列），那当然是直接使用单线程会更快一些。但如果要计算的东西比较复杂，计算机又是多核的情况下，就可以充分利用多核CPU来提高计算速度。

Java 8 Stream的并行操作底层就是用到了Fork/Join框架

## [第十九章 Java 8 Stream并行计算原理](http://concurrent.redspider.group/article/03/19.html)


## [第二十章 计划任务](http://concurrent.redspider.group/article/03/20.html)
自JDK 1.5 开始，JDK提供了ScheduledThreadPoolExecutor类用于计划任务（又称定时任务），这个类有两个用途：

- 在给定的延迟之后运行任务
- 周期性重复执行任务

在这之前，是使用Timer类来完成定时任务的，但是Timer有缺陷：
```text
Timer是单线程模式；
如果在执行任务期间某个TimerTask耗时较久，那么就会影响其它任务的调度；
Timer的任务调度是基于绝对时间的，对系统时间敏感；
Timer不会捕获执行TimerTask时所抛出的异常，由于Timer是单线程，所以一旦出现异常，则线程就会终止，其他任务也得不到执行
```

### 20.1 使用案例

### 20.2 类结构
```text
public class ScheduledThreadPoolExecutor extends ThreadPoolExecutor
    implements ScheduledExecutorService {
```

重点理解一下两个方法：
```text
scheduleAtFixedRate

该方法在initialDelay时长后第一次执行任务，以后每隔period时长，再次执行任务。注意，period是从任务开始执行算起的。开始执行任务后，定时器每隔period时长检查该任务是否完成，如果完成则再次启动任务，否则等该任务结束后才再次启动任务。

scheduleWithFixDelay

该方法在initialDelay时长后第一次执行任务，以后每当任务执行完成后，等待delay时长，再次执行任务。
```

总结一下run方法的执行过程：
```text
1. 如果当前线程池运行状态不可以执行任务，取消该任务，然后直接返回，否则执行步骤2；
2. 如果不是周期性任务，调用FutureTask中的run方法执行，会设置执行结果，然后直接返回，否则执行步骤3；
3. 如果是周期性任务，调用FutureTask中的runAndReset方法执行，不会设置执行结果，然后直接返回，否则执行步骤4和步骤5；
4. 计算下次执行该任务的具体时间；
5. 重复执行任务。
```
